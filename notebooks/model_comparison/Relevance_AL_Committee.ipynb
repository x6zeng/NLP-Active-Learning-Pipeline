{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e04c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import unidecode\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4226012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022 = pd.read_csv('/Users/yunyihuang/Desktop/NLP-Active-Learning-Pipeline/data/tweet_data_2022.csv')\n",
    "df_2023 = pd.read_csv('/Users/yunyihuang/Desktop/NLP-Active-Learning-Pipeline/data/tweet_data_2023.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6665c20",
   "metadata": {},
   "source": [
    "### Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b6b2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_number = 3\n",
    "random_state = 42\n",
    "categories = ['Bucket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09f8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_bucket(bucket):\n",
    "    if ((bucket == '1.0') | (bucket == '1')):\n",
    "        return '1'\n",
    "    elif ((bucket == '2') | (bucket == '3') | (bucket == '2.0') | (bucket == '3.0')):\n",
    "        return '2 or 3'\n",
    "    else:\n",
    "        return bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3034b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if type(text) == np.float64:\n",
    "        return \"\"\n",
    "    temp = text.lower() # to lower case\n",
    "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp) # remove @s\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp) # remove hashtags\n",
    "    temp = re.sub(r'http\\S+', '', temp) # remove links\n",
    "    temp = re.sub(r\"www.\\S+\", \"\", temp) # remove links\n",
    "    temp = re.sub(r'\\n|[^a-zA-Z]', ' ', temp) # remove punctuation\n",
    "    temp = temp.replace(\"\\n\", \" \").split()\n",
    "    temp = [w for w in temp if not w in stopwords_] # remove stopwords\n",
    "    temp = [w for w in temp if not w.isdigit()] # remove numbers\n",
    "    temp = [unidecode.unidecode(w) for w in temp] # turn non-enlish letters to english letters\n",
    "    temp = \" \".join(word for word in temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04826dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(df, ratio, time):\n",
    "    #partiton\n",
    "    if time:\n",
    "        df.sort_values(by=['date'], inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "    df_rows = df.shape[0]\n",
    "    seed_num = math.floor(df_rows * ratio[0])\n",
    "    seed = df[:seed_num]\n",
    "    unlabeled_num = seed_num + (math.floor(df_rows * ratio[1]))\n",
    "    unlabeled = df[seed_num:unlabeled_num]\n",
    "    test = df[unlabeled_num:]\n",
    "    return seed, unlabeled, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d091725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(seed):\n",
    "    cv = 5\n",
    "    train, test = train_test_split(seed, random_state=random_state, test_size=0.2, shuffle=True)\n",
    "    X_train, X_test, Y_train, Y_test = train[['text_cleaned']], test[['text_cleaned']], train[['Bucket']], test[['Bucket']]\n",
    "    #Wrap in ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tf\", CountVectorizer(stop_words=stopwords_), 'text_cleaned'),\n",
    "            (\"tfidf\", TfidfVectorizer(stop_words=stopwords_), 'text_cleaned')]\n",
    "    )\n",
    "    #Define the model\n",
    "    model_lst = [\n",
    "                SVC(),\n",
    "                KNeighborsClassifier(),\n",
    "                DecisionTreeClassifier(),\n",
    "                RandomForestClassifier(),\n",
    "                AdaBoostClassifier(),\n",
    "            ]\n",
    "    \n",
    "    pl_preds = []\n",
    "    for model in model_lst:\n",
    "        #Build the pipeline\n",
    "        pipeline = Pipeline([\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('clf', OneVsRestClassifier(model, n_jobs=1)),\n",
    "                ])\n",
    "        #Train the model\n",
    "        pipeline.fit(X_train, Y_train)\n",
    "        # compute the testing accuracy\n",
    "        prediction = pipeline.predict(pd.DataFrame(X_test))\n",
    "        pl_preds.append([pipeline, prediction])\n",
    "        \n",
    "    #Saves all the model pipelines\n",
    "    pipelines = [x[0] for x in pl_preds]\n",
    "    #Saves all the model predictions\n",
    "    all_preds = np.array([x[1] for x in pl_preds]).transpose()\n",
    "    #Find the mode in all preds\n",
    "    final_preds = [mode(i) for i in all_preds]\n",
    "    accuracy = accuracy_score(Y_test,final_preds)\n",
    "    return pipelines, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "836d90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(lst):\n",
    "    unique_num = list(set(lst))\n",
    "    entropy = 0\n",
    "    for i in range(len(unique_num)):\n",
    "        label = unique_num[i]\n",
    "        prob = sum(np.array(lst) == label)/len(lst)\n",
    "        entropy += prob * math.log2(1/prob)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39aef465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_unlabeled(pipelines, unlabeled):\n",
    "    unlabeled_x = unlabeled[['text_cleaned']]\n",
    "    unlabeled_y = unlabeled[['Bucket']]\n",
    "    all_preds = np.array([pl.predict(unlabeled_x) for pl in pipelines]).transpose()\n",
    "    unlabeled['all_preds'] = list(all_preds)\n",
    "    unlabeled['entropy'] = unlabeled['all_preds'].apply(calc_entropy)\n",
    "    unlabeled.sort_values(by=['entropy'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4a29a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learning(pipelines, seed, unlabeled, instances):\n",
    "    # Sort the unlabeled data based on informativeness level\n",
    "    choose_unlabeled(pipelines, unlabeled)\n",
    "    # Update the unlabeled data and the info_data\n",
    "    info_data, unlabeled = unlabeled.iloc[:instances], unlabeled.iloc[instances:]\n",
    "    # Add selected data to the training set\n",
    "    seed = pd.concat([seed, info_data[['date', 'text', 'Bucket', 'text_cleaned']]])\n",
    "    pipelines, accuracy = train_model(seed)\n",
    "    return pipelines, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03fc5bf",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca671fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_stopwords = stopwords.words('english')\n",
    "additional_stopwords = ['none']\n",
    "original_stopwords.extend(additional_stopwords)\n",
    "stopwords_ = set(original_stopwords)\n",
    "\n",
    "#Selects only the tweets about China\n",
    "df = df_2022[df_2022['country']=='China']\n",
    "df = df[['date', 'text', 'id', 'Bucket', 'SentimentScore']]\n",
    "\n",
    "#Shuffle the data\n",
    "df = df.sample(frac=1, replace=False, random_state=1) \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#Standardized the bucket label\n",
    "df['Bucket'] = df['Bucket'].apply(standardize_bucket)\n",
    "#Remove tweets that are in both buckets\n",
    "df_bucket_count = pd.DataFrame(df.groupby('id')['Bucket'].nunique())\n",
    "df_bucket_count.reset_index(inplace=True)\n",
    "df_bucket_count.columns = ['tweet_id', 'bucket_num']\n",
    "df = df.merge(df_bucket_count, left_on='id', right_on='tweet_id')\n",
    "df = df[df['bucket_num'] == 1]\n",
    "#Remove tweets without a bucket (null)\n",
    "df = df[(df['Bucket'] == '1') | (df['Bucket'] == '2 or 3')]\n",
    "#Remove duplicates\n",
    "df = df.drop_duplicates(subset=['id']).reset_index(drop=True)\n",
    "df = df[['date', 'text', 'Bucket']]\n",
    "df[\"text_cleaned\"] = [clean_text(t) for t in df[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e7f3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(df, model_names, training_method, balance, sampling_size, sort_by_time, partition_ratio):\n",
    "    output = {}\n",
    "    output['model_names'] = model_names\n",
    "    output['training_method'] = training_method #random_sampling, active_learning\n",
    "    output['balance'] = balance\n",
    "    output['sampling_size'] = sampling_size\n",
    "    output['sort_by_time'] = sort_by_time\n",
    "    output['partition_ratio'] = partition_ratio\n",
    "    accuracy_lst, f1_lst, precision_lst, recall_lst, specificity_lst = [], [], [], [], []\n",
    "    \n",
    "    for i in range(5):\n",
    "        # 1. Balance dataset \n",
    "        df_1, df_2_3 = df[df.Bucket=='1'], df[df.Bucket=='2 or 3']\n",
    "        df_lst = [df_1, df_2_3]\n",
    "\n",
    "        # 1.1 Balance the label distribution  (50% Bucket 1 vs. 50% Non-Bucket 1)\n",
    "        if balance:\n",
    "            sample_size = min(df_1.shape[0], df_2_3.shape[0])\n",
    "            if df_1.shape[0] > sample_size:\n",
    "                df_1 = resample(df_1, replace=False, n_samples=sample_size, random_state=random_state)\n",
    "            if df_2_3.shape[0] > sample_size:\n",
    "                df_2_3 = resample(df_2_3, replace=False, n_samples=sample_size, random_state=random_state)\n",
    "\n",
    "        # 1.2 Keep the natural label distribution\n",
    "        seed_1, unlabeled_1, test_1 = partition_data(df_1, partition_ratio, sort_by_time)\n",
    "        seed_2_3, unlabeled_2_3, test_2_3 = partition_data(df_2_3, partition_ratio, sort_by_time)\n",
    "        seed, unlabeled, test = pd.concat([seed_1, seed_2_3]), pd.concat([unlabeled_1, unlabeled_2_3]), pd.concat([test_1, test_2_3])\n",
    "        output['seed_size'], output['unlabeled_size'], output['test_size'] = seed.shape[0], unlabeled.shape[0], test.shape[0]\n",
    "\n",
    "        initial_seed = seed.copy()\n",
    "        initial_unlabeled = unlabeled.copy()\n",
    "\n",
    "        # 2. Train the model\n",
    "        initial_pipelines, initial_accuracy = train_model(initial_seed)\n",
    "\n",
    "        # 3. Active Learning\n",
    "        if sampling_size == 0:\n",
    "            pipelines, accuracy = initial_pipelines, initial_accuracy\n",
    "\n",
    "        # 3.1 Initial Model + Random Sampling\n",
    "        elif training_method == 'random_sampling':\n",
    "            if initial_unlabeled.shape[0] >= sampling_size:\n",
    "                sample_unlabeled = initial_unlabeled.sample(n=sampling_size, replace=False, random_state=i)\n",
    "            else:\n",
    "                sample_unlabeled = initial_unlabeled.sample(n=sampling_size, replace=True, random_state=i)\n",
    "            seed_and_sample_unlabeled_df = pd.concat([initial_seed, sample_unlabeled])\n",
    "            pipelines, accuracy = train_model(seed_and_sample_unlabeled_df)\n",
    "\n",
    "        # 3.2 Initial Model + Active Learning\n",
    "        else:\n",
    "            pipelines, accuracy = active_learning(initial_pipelines, initial_seed, initial_unlabeled, sampling_size)\n",
    "\n",
    "        # 4. Report Model Accuracy\n",
    "        X_test, Y_test = test[['text_cleaned']], test[['Bucket']]\n",
    "\n",
    "\n",
    "        pl_preds = []\n",
    "        for pl in pipelines:\n",
    "            # compute the testing accuracy\n",
    "            prediction = pl.predict(pd.DataFrame(X_test))\n",
    "            pl_preds.append([pl, prediction])\n",
    "\n",
    "        #Saves all the model predictions\n",
    "        all_preds = np.array([x[1] for x in pl_preds]).transpose()\n",
    "        #Find the mode in all preds\n",
    "        prediction = [mode(i) for i in all_preds]\n",
    "        accuracy = round(accuracy_score(Y_test, prediction), round_number)\n",
    "        f1 = round(f1_score(np.array(Y_test), prediction, pos_label='1'), round_number)\n",
    "        precision = round(precision_score(np.array(Y_test), prediction, pos_label='1', average='binary'), round_number)\n",
    "        recall = round(recall_score(np.array(Y_test), prediction, pos_label='1', average='binary'), round_number)\n",
    "        specificity = round(recall_score(np.array(Y_test), prediction, pos_label='2 or 3', average='binary'), round_number)\n",
    "        \n",
    "        accuracy_lst.append(accuracy)\n",
    "        f1_lst.append(f1)\n",
    "        precision_lst.append(precision) \n",
    "        recall_lst.append(recall) \n",
    "        specificity_lst.append(specificity) \n",
    "    \n",
    "    output['accuracy'] = np.mean(accuracy_lst)\n",
    "    output['f1_score'] = np.mean(f1_lst)\n",
    "    output['precision'] = np.mean(precision_lst)\n",
    "    output['recall'] = np.mean(recall_lst)\n",
    "    output['specificity'] = np.mean(specificity_lst)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4063903",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_method = ['random_sampling', 'active_learning']\n",
    "balanced = [True, False]\n",
    "sampling_size = [0, 200, 400, 600]\n",
    "sort_by_time = [True, False]\n",
    "partition_ratio = [[0.1, 0.45, 0.45], [0.5, 0.25, 0.25], [0.9, 0.05, 0.05]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5848d2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'stop_words' parameter of CountVectorizer must be a str among {'english'}, an instance of 'list' or None. Got {\"that'll\", 'are', 'ourselves', 'once', 'weren', 'y', 'hers', 'have', 'd', \"hasn't\", 'only', 'none', 'if', 'out', 'up', 've', \"doesn't\", 'being', 'during', 'themselves', 'such', 'my', 'under', 'any', 'what', 'll', 'some', 're', 'did', 'for', 'do', 'is', 'then', \"weren't\", 'he', \"didn't\", \"you've\", 'again', \"don't\", 'too', 'through', 'were', \"aren't\", 'there', 'be', 'on', 'haven', 'herself', 'wouldn', 'yourself', 'she', 'was', 'most', 'where', 'both', \"mustn't\", 'needn', 'doing', 'before', 'doesn', 'should', 'shouldn', 'no', 'against', 'm', 'but', 'has', 'am', 'hadn', 'as', 'that', 'didn', 'in', 'them', 'more', 'me', 'him', 'o', 'myself', 'ours', \"isn't\", 'same', 's', 'they', 'mightn', 'so', 'not', 'ma', 'your', \"you'd\", 'now', \"mightn't\", 'because', 'further', 'won', 'been', 'when', 'which', 'aren', 'shan', 'about', 'it', 'an', 'don', 'their', 'between', 'those', \"you're\", 'theirs', 'the', 'its', 'off', 'had', 'or', \"needn't\", 'of', 'can', 'yourselves', \"won't\", 'why', \"wouldn't\", 'very', 'into', 'after', 'you', 'how', 'having', 'at', \"haven't\", 'ain', 'will', 'yours', 'does', 'with', 'than', \"wasn't\", \"shouldn't\", 'i', 'who', \"couldn't\", 'hasn', 'until', 'here', 'couldn', 'own', 'nor', 'while', 'by', 'itself', 't', 'below', 'from', 'mustn', 'whom', 'we', \"shan't\", 'few', \"you'll\", 'all', 'down', 'a', 'to', \"she's\", \"hadn't\", 'his', 'himself', 'isn', 'her', 'our', \"it's\", 'wasn', 'this', 'and', 'above', 'other', 'each', \"should've\", 'these', 'over', 'just'} instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6r/ljk6dgwn77q618x071444l0r0000gn/T/ipykernel_26151/2888771998.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpartition_ratio\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                         \u001b[0mmodel_result_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6r/ljk6dgwn77q618x071444l0r0000gn/T/ipykernel_26151/3484219116.py\u001b[0m in \u001b[0;36mtrial\u001b[0;34m(df, model_names, training_method, balance, sampling_size, sort_by_time, partition_ratio)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# 2. Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0minitial_pipelines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# 3. Active Learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6r/ljk6dgwn77q618x071444l0r0000gn/T/ipykernel_26151/1354425305.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 ])\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# compute the testing accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \"\"\"\n\u001b[1;32m    400\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    656\u001b[0m         )\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             return Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    659\u001b[0m                 delayed(func)(\n\u001b[1;32m    660\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1367\u001b[0m             )\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_ngram_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0maccepted\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \"\"\"\n\u001b[0;32m--> 600\u001b[0;31m         validate_parameter_constraints(\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 )\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             raise InvalidParameterError(\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0;34mf\"The {param_name!r} parameter of {caller_name} must be\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;34mf\" {constraints_str}. Got {param_val!r} instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'stop_words' parameter of CountVectorizer must be a str among {'english'}, an instance of 'list' or None. Got {\"that'll\", 'are', 'ourselves', 'once', 'weren', 'y', 'hers', 'have', 'd', \"hasn't\", 'only', 'none', 'if', 'out', 'up', 've', \"doesn't\", 'being', 'during', 'themselves', 'such', 'my', 'under', 'any', 'what', 'll', 'some', 're', 'did', 'for', 'do', 'is', 'then', \"weren't\", 'he', \"didn't\", \"you've\", 'again', \"don't\", 'too', 'through', 'were', \"aren't\", 'there', 'be', 'on', 'haven', 'herself', 'wouldn', 'yourself', 'she', 'was', 'most', 'where', 'both', \"mustn't\", 'needn', 'doing', 'before', 'doesn', 'should', 'shouldn', 'no', 'against', 'm', 'but', 'has', 'am', 'hadn', 'as', 'that', 'didn', 'in', 'them', 'more', 'me', 'him', 'o', 'myself', 'ours', \"isn't\", 'same', 's', 'they', 'mightn', 'so', 'not', 'ma', 'your', \"you'd\", 'now', \"mightn't\", 'because', 'further', 'won', 'been', 'when', 'which', 'aren', 'shan', 'about', 'it', 'an', 'don', 'their', 'between', 'those', \"you're\", 'theirs', 'the', 'its', 'off', 'had', 'or', \"needn't\", 'of', 'can', 'yourselves', \"won't\", 'why', \"wouldn't\", 'very', 'into', 'after', 'you', 'how', 'having', 'at', \"haven't\", 'ain', 'will', 'yours', 'does', 'with', 'than', \"wasn't\", \"shouldn't\", 'i', 'who', \"couldn't\", 'hasn', 'until', 'here', 'couldn', 'own', 'nor', 'while', 'by', 'itself', 't', 'below', 'from', 'mustn', 'whom', 'we', \"shan't\", 'few', \"you'll\", 'all', 'down', 'a', 'to', \"she's\", \"hadn't\", 'his', 'himself', 'isn', 'her', 'our', \"it's\", 'wasn', 'this', 'and', 'above', 'other', 'each', \"should've\", 'these', 'over', 'just'} instead."
     ]
    }
   ],
   "source": [
    "model_result_df = pd.DataFrame()\n",
    "index = 1\n",
    "model_name = \"SVC, KNN, Decision Tree, Random Forest, AdaBoost\"\n",
    "for tm in training_method:\n",
    "    for b in balanced:\n",
    "        for ss in sampling_size:\n",
    "            for t in sort_by_time:\n",
    "                for r in partition_ratio:\n",
    "                    print(index)\n",
    "                    model_output = trial(df, model_name, tm, b, ss, t, r)\n",
    "                    if index == 0:\n",
    "                        model_result_df = pd.DataFrame(model_output, index=index)\n",
    "                    else:\n",
    "                        model_result_df = model_result_df.append(pd.DataFrame([model_output],index=[index]))\n",
    "                    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bce332de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_names</th>\n",
       "      <th>training_method</th>\n",
       "      <th>balance</th>\n",
       "      <th>sampling_size</th>\n",
       "      <th>sort_by_time</th>\n",
       "      <th>partition_ratio</th>\n",
       "      <th>seed_size</th>\n",
       "      <th>unlabeled_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.1, 0.45, 0.45]</td>\n",
       "      <td>412</td>\n",
       "      <td>1854</td>\n",
       "      <td>1858</td>\n",
       "      <td>0.5702</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>0.5778</td>\n",
       "      <td>0.5196</td>\n",
       "      <td>0.6204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>2062</td>\n",
       "      <td>1030</td>\n",
       "      <td>1032</td>\n",
       "      <td>0.7346</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.7190</td>\n",
       "      <td>0.7712</td>\n",
       "      <td>0.6980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.9, 0.05, 0.05]</td>\n",
       "      <td>3710</td>\n",
       "      <td>206</td>\n",
       "      <td>208</td>\n",
       "      <td>0.7644</td>\n",
       "      <td>0.7846</td>\n",
       "      <td>0.7232</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>0.6712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.1, 0.45, 0.45]</td>\n",
       "      <td>412</td>\n",
       "      <td>1854</td>\n",
       "      <td>1858</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.6462</td>\n",
       "      <td>0.7654</td>\n",
       "      <td>0.5596</td>\n",
       "      <td>0.8286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>2062</td>\n",
       "      <td>1030</td>\n",
       "      <td>1032</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.7434</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>0.8116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>5073</td>\n",
       "      <td>2536</td>\n",
       "      <td>2538</td>\n",
       "      <td>0.8314</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.8284</td>\n",
       "      <td>0.9942</td>\n",
       "      <td>0.1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.9, 0.05, 0.05]</td>\n",
       "      <td>9131</td>\n",
       "      <td>507</td>\n",
       "      <td>509</td>\n",
       "      <td>0.8230</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8190</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.1440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.1, 0.45, 0.45]</td>\n",
       "      <td>1014</td>\n",
       "      <td>4565</td>\n",
       "      <td>4568</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.8946</td>\n",
       "      <td>0.8220</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.1670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>5073</td>\n",
       "      <td>2536</td>\n",
       "      <td>2538</td>\n",
       "      <td>0.8446</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.8470</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.9, 0.05, 0.05]</td>\n",
       "      <td>9131</td>\n",
       "      <td>507</td>\n",
       "      <td>509</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.9106</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.2884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         model_names  training_method  \\\n",
       "1   SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling   \n",
       "2   SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling   \n",
       "3   SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling   \n",
       "4   SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling   \n",
       "5   SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling   \n",
       "..                                               ...              ...   \n",
       "92  SVC, KNN, Decision Tree, Random Forest, AdaBoost  active_learning   \n",
       "93  SVC, KNN, Decision Tree, Random Forest, AdaBoost  active_learning   \n",
       "94  SVC, KNN, Decision Tree, Random Forest, AdaBoost  active_learning   \n",
       "95  SVC, KNN, Decision Tree, Random Forest, AdaBoost  active_learning   \n",
       "96  SVC, KNN, Decision Tree, Random Forest, AdaBoost  active_learning   \n",
       "\n",
       "    balance  sampling_size  sort_by_time    partition_ratio  seed_size  \\\n",
       "1      True              0          True  [0.1, 0.45, 0.45]        412   \n",
       "2      True              0          True  [0.5, 0.25, 0.25]       2062   \n",
       "3      True              0          True  [0.9, 0.05, 0.05]       3710   \n",
       "4      True              0         False  [0.1, 0.45, 0.45]        412   \n",
       "5      True              0         False  [0.5, 0.25, 0.25]       2062   \n",
       "..      ...            ...           ...                ...        ...   \n",
       "92    False            600          True  [0.5, 0.25, 0.25]       5073   \n",
       "93    False            600          True  [0.9, 0.05, 0.05]       9131   \n",
       "94    False            600         False  [0.1, 0.45, 0.45]       1014   \n",
       "95    False            600         False  [0.5, 0.25, 0.25]       5073   \n",
       "96    False            600         False  [0.9, 0.05, 0.05]       9131   \n",
       "\n",
       "    unlabeled_size  test_size  accuracy  f1_score  precision  recall  \\\n",
       "1             1854       1858    0.5702    0.5470     0.5778  0.5196   \n",
       "2             1030       1032    0.7346    0.7440     0.7190  0.7712   \n",
       "3              206        208    0.7644    0.7846     0.7232  0.8578   \n",
       "4             1854       1858    0.6940    0.6462     0.7654  0.5596   \n",
       "5             1030       1032    0.7576    0.7434     0.7886  0.7030   \n",
       "..             ...        ...       ...       ...        ...     ...   \n",
       "92            2536       2538    0.8314    0.9036     0.8284  0.9942   \n",
       "93             507        509    0.8230    0.9000     0.8190  0.9980   \n",
       "94            4565       4568    0.8160    0.8946     0.8220  0.9814   \n",
       "95            2536       2538    0.8446    0.9098     0.8470  0.9824   \n",
       "96             507        509    0.8462    0.9106     0.8440  0.9892   \n",
       "\n",
       "    specificity  \n",
       "1        0.6204  \n",
       "2        0.6980  \n",
       "3        0.6712  \n",
       "4        0.8286  \n",
       "5        0.8116  \n",
       "..          ...  \n",
       "92       0.1930  \n",
       "93       0.1440  \n",
       "94       0.1670  \n",
       "95       0.3050  \n",
       "96       0.2884  \n",
       "\n",
       "[96 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c583f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result_df.to_csv('bucket_committee_model_result.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d908a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd8b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaeb2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db8c66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf644f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c54863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4b042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22e2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66099f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df87846b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
