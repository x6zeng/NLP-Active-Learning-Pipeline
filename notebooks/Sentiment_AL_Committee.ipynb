{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e04c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import unidecode\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4226012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022 = pd.read_csv('../data/tweet_data_2022.csv')\n",
    "df_2023 = pd.read_csv('../data/tweet_data_2023.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6665c20",
   "metadata": {},
   "source": [
    "### Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b6b2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_number = 3\n",
    "random_state = 42\n",
    "categories = ['SentimentScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09f8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_sent(sent):\n",
    "    if ((sent == 0) | (sent == 1) | (sent == 2)):\n",
    "        return 'Negative'\n",
    "    elif (sent == 3):\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3034b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if type(text) == np.float:\n",
    "        return \"\"\n",
    "    temp = text.lower() # to lower case\n",
    "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp) # remove @s\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp) # remove hashtags\n",
    "    temp = re.sub(r'http\\S+', '', temp) # remove links\n",
    "    temp = re.sub(r\"www.\\S+\", \"\", temp) # remove links\n",
    "    temp = re.sub(r'\\n|[^a-zA-Z]', ' ', temp) # remove punctuation\n",
    "    temp = temp.replace(\"\\n\", \" \").split()\n",
    "    temp = [w for w in temp if not w in stopwords_] # remove stopwords\n",
    "    temp = [w for w in temp if not w.isdigit()] # remove numbers\n",
    "    temp = [unidecode.unidecode(w) for w in temp] # turn non-enlish letters to english letters\n",
    "    temp = \" \".join(word for word in temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04826dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(df, ratio, time):\n",
    "    #partiton\n",
    "    if time:\n",
    "        df.sort_values(by=['date'], inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "    df_rows = df.shape[0]\n",
    "    seed_num = math.floor(df_rows * ratio[0])\n",
    "    seed = df[:seed_num]\n",
    "    unlabeled_num = seed_num + (math.floor(df_rows * ratio[1]))\n",
    "    unlabeled = df[seed_num:unlabeled_num]\n",
    "    test = df[unlabeled_num:]\n",
    "    return seed, unlabeled, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d091725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(seed):\n",
    "    cv = 5\n",
    "    train, test = train_test_split(seed, random_state=random_state, test_size=0.2, shuffle=True)\n",
    "    X_train, X_test, Y_train, Y_test = train[['text_cleaned']], test[['text_cleaned']], train[['SentimentScore']], test[['SentimentScore']]\n",
    "    #Wrap in ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tf\", CountVectorizer(stop_words=stopwords_), 'text_cleaned'),\n",
    "            (\"tfidf\", TfidfVectorizer(stop_words=stopwords_), 'text_cleaned')]\n",
    "    )\n",
    "    #Define the model\n",
    "    model_lst = [\n",
    "                SVC(),\n",
    "                KNeighborsClassifier(),\n",
    "                DecisionTreeClassifier(),\n",
    "                RandomForestClassifier(),\n",
    "                AdaBoostClassifier(),\n",
    "#                  SVC(kernel='rbf', probability=True, random_state=random_state), #SVC RBF\n",
    "#                  SVC(kernel='poly', probability=True, degree=4, random_state=random_state), #SVC Poly\n",
    "#                  BernoulliNB(fit_prior=True, class_prior=None), #Naive Bayes\n",
    "#                  RandomForestClassifier(random_state=random_state), #Random Forest\n",
    "#                  LogisticRegression(solver='sag', random_state=random_state), #Logistic Regression (Ridge)\n",
    "#                  LogisticRegression(C=1, penalty='l1', solver='liblinear', random_state=random_state), #Logistic Regression (Lasso)\n",
    "            ]\n",
    "#     model = model_lst[model_index]\n",
    "    \n",
    "    pl_preds = []\n",
    "    for model in model_lst:\n",
    "        #Build the pipeline\n",
    "        pipeline = Pipeline([\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('clf', OneVsRestClassifier(model, n_jobs=1)),\n",
    "                ])\n",
    "        #Train the model\n",
    "        pipeline.fit(X_train, Y_train)\n",
    "        # compute the testing accuracy\n",
    "        prediction = pipeline.predict(pd.DataFrame(X_test))\n",
    "        pl_preds.append([pipeline, prediction])\n",
    "        \n",
    "    #Saves all the model pipelines\n",
    "    pipelines = [x[0] for x in pl_preds]\n",
    "    #Saves all the model predictions\n",
    "    all_preds = np.array([x[1] for x in pl_preds]).transpose()\n",
    "    #Find the mode in all preds\n",
    "    final_preds = [mode(i) for i in all_preds]\n",
    "    accuracy = accuracy_score(Y_test,final_preds)\n",
    "    return pipelines, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "836d90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(lst):\n",
    "    unique_num = list(set(lst))\n",
    "    entropy = 0\n",
    "    for i in range(len(unique_num)):\n",
    "        label = unique_num[i]\n",
    "        prob = sum(np.array(lst) == label)/len(lst)\n",
    "        entropy += prob * math.log2(1/prob)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39aef465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_unlabeled(pipelines, unlabeled):\n",
    "    unlabeled_x = unlabeled[['text_cleaned']]\n",
    "    unlabeled_y = unlabeled[['SentimentScore']]\n",
    "    all_preds = np.array([pl.predict(unlabeled_x) for pl in pipelines]).transpose()\n",
    "    unlabeled['all_preds'] = list(all_preds)\n",
    "    unlabeled['entropy'] = unlabeled['all_preds'].apply(calc_entropy)\n",
    "    unlabeled.sort_values(by=['entropy'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4a29a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learning(pipelines, seed, unlabeled, instances):\n",
    "    # Sort the unlabeled data based on informativeness level\n",
    "    choose_unlabeled(pipelines, unlabeled)\n",
    "    # Update the unlabeled data and the info_data\n",
    "    info_data, unlabeled = unlabeled.iloc[:instances], unlabeled.iloc[instances:]\n",
    "    # Add selected data to the training set\n",
    "    seed = pd.concat([seed, info_data[['date', 'text', 'SentimentScore', 'text_cleaned']]])\n",
    "    pipelines, accuracy = train_model(seed)\n",
    "    return pipelines, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03fc5bf",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca671fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_stopwords = stopwords.words('english')\n",
    "additional_stopwords = ['none']\n",
    "original_stopwords.extend(additional_stopwords)\n",
    "stopwords_ = set(original_stopwords)\n",
    "\n",
    "#Selects only the tweets about China\n",
    "df = df_2022[df_2022['country']=='China']\n",
    "df = df[['date', 'text', 'id', 'Bucket', 'SentimentScore']]\n",
    "\n",
    "#Shuffle the data\n",
    "df = df.sample(frac=1, replace=False, random_state=1) \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Step 1: Remove tweets that do not have sentiment score\n",
    "#Step 2: Average the sentiment score for each unique tweet\n",
    "df = df.copy()[['date', 'text', 'id', 'SentimentScore']]\n",
    "df.dropna(subset=['SentimentScore'], inplace=True)\n",
    "\n",
    "df = pd.DataFrame(df.groupby(['date', 'text', 'id'])['SentimentScore'].mean())\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "#Remove ambiguous labels\n",
    "range_lst = [0, 1, 2, 3, 4, 5]\n",
    "df = df[df['SentimentScore'].apply(lambda x: True if x in range_lst else False)]\n",
    "df['SentimentScore'] = df['SentimentScore'].apply(standardize_sent)\n",
    "\n",
    "#Remove duplicates\n",
    "df = df.drop_duplicates(subset=['id']).reset_index(drop=True)\n",
    "df = df[['date', 'text', 'SentimentScore']]\n",
    "df[\"text_cleaned\"] = [clean_text(t) for t in df[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e7f3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(df, model_names, training_method, balance, sampling_size, sort_by_time, partition_ratio):\n",
    "    output = {}\n",
    "    output['model_names'] = model_names\n",
    "    output['training_method'] = training_method #random_sampling, active_learning\n",
    "    output['balance'] = balance\n",
    "    output['sampling_size'] = sampling_size\n",
    "    output['sort_by_time'] = sort_by_time\n",
    "    output['partition_ratio'] = partition_ratio\n",
    "        \n",
    "    # 1. Balance dataset \n",
    "    df_1, df_2, df_3 = df[df.SentimentScore=='Negative'], df[df.SentimentScore=='Neutral'], df[df.SentimentScore=='Positive']\n",
    "\n",
    "    # 1.1 Balance the label distribution  (33% Negative vs. 33% Neutral vs. 33% Positive)\n",
    "    if balance:\n",
    "        sample_size = min(df_1.shape[0], df_2.shape[0], df_3.shape[0])\n",
    "        if df_1.shape[0] > sample_size:\n",
    "            df_1 = resample(df_1, replace=False, n_samples=sample_size, random_state=random_state)\n",
    "        if df_2.shape[0] > sample_size:\n",
    "            df_2 = resample(df_2, replace=False, n_samples=sample_size, random_state=random_state)\n",
    "        if df_3.shape[0] > sample_size:\n",
    "            df_3 = resample(df_3, replace=False, n_samples=sample_size, random_state=random_state)\n",
    "\n",
    "    # 1.2 Keep the natural label distribution\n",
    "    seed_1, unlabeled_1, test_1 = partition_data(df_1, partition_ratio, sort_by_time)\n",
    "    seed_2, unlabeled_2, test_2 = partition_data(df_2, partition_ratio, sort_by_time)\n",
    "    seed_3, unlabeled_3, test_3 = partition_data(df_3, partition_ratio, sort_by_time)\n",
    "    seed, unlabeled, test = pd.concat([seed_1, seed_2, seed_3]), pd.concat([unlabeled_1, unlabeled_2, unlabeled_3]), pd.concat([test_1, test_2, test_3])\n",
    "    output['seed_size'], output['unlabeled_size'], output['test_size'] = seed.shape[0], unlabeled.shape[0], test.shape[0]\n",
    "    \n",
    "    initial_seed = seed.copy()\n",
    "    initial_unlabeled = unlabeled.copy()\n",
    "    \n",
    "    # 2. Train the model\n",
    "    initial_pipelines, initial_accuracy = train_model(initial_seed)\n",
    "    \n",
    "    # 3. Active Learning\n",
    "    if sampling_size == 0:\n",
    "        pipelines, accuracy = initial_pipelines, initial_accuracy\n",
    "        \n",
    "    # 3.1 Initial Model + Random Sampling\n",
    "    elif training_method == 'random_sampling':\n",
    "        if initial_unlabeled.shape[0] >= sampling_size:\n",
    "            sample_unlabeled = initial_unlabeled.sample(n=sampling_size, replace=False, random_state=random_state)\n",
    "        else:\n",
    "            sample_unlabeled = initial_unlabeled.sample(n=sampling_size, replace=True, random_state=random_state)\n",
    "        seed_and_sample_unlabeled_df = pd.concat([initial_seed, sample_unlabeled])\n",
    "        pipelines, accuracy = train_model(seed_and_sample_unlabeled_df)\n",
    "        \n",
    "    # 3.2 Initial Model + Active Learning\n",
    "    else:\n",
    "        pipelines, accuracy = active_learning(initial_pipelines, initial_seed, initial_unlabeled, sampling_size)\n",
    "\n",
    "    # 4. Report Model Accuracy\n",
    "    X_test, Y_test = test[['text_cleaned']], test[['SentimentScore']]\n",
    "\n",
    "    pl_preds = []\n",
    "    for pl in pipelines:\n",
    "        # compute the testing accuracy\n",
    "        prediction = pl.predict(pd.DataFrame(X_test))\n",
    "        pl_preds.append([pl, prediction])\n",
    "        \n",
    "    #Saves all the model predictions\n",
    "    all_preds = np.array([x[1] for x in pl_preds]).transpose()\n",
    "    #Find the mode in all preds\n",
    "    prediction = [mode(i) for i in all_preds]\n",
    "    accuracy = round(accuracy_score(Y_test, prediction), round_number)\n",
    "    f1_micro = round(f1_score(np.array(Y_test), prediction, average='micro'), round_number)\n",
    "    f1_macro = round(f1_score(np.array(Y_test), prediction, average='macro'), round_number)\n",
    "    f1_weighted = round(f1_score(np.array(Y_test), prediction, average='weighted'), round_number)\n",
    "    \n",
    "    precision_micro = round(precision_score(np.array(Y_test), prediction, average='micro'), round_number)\n",
    "    precision_macro = round(precision_score(np.array(Y_test), prediction, average='macro'), round_number)\n",
    "    precision_weighted = round(precision_score(np.array(Y_test), prediction, average='weighted'), round_number)\n",
    "        \n",
    "    recall_micro = round(recall_score(np.array(Y_test), prediction, average='micro'), round_number)\n",
    "    recall_macro = round(recall_score(np.array(Y_test), prediction, average='macro'), round_number)\n",
    "    recall_weighted = round(recall_score(np.array(Y_test), prediction, average='weighted'), round_number)\n",
    "    \n",
    "    output['accuracy'] = accuracy\n",
    "    output['f1_micro'], output['f1_macro'], output['f1_weighted'] = f1_micro, f1_macro, f1_weighted\n",
    "    output['precision_micro'], output['precision_macro'], output['precision_weighted'] = precision_micro, precision_macro, precision_weighted\n",
    "    output['recall_micro'], output['recall_macro'], output['recall_weighted'] = recall_micro, recall_macro, recall_weighted\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4063903",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_method = ['random_sampling', 'active_learning']\n",
    "balanced = [True, False]\n",
    "sampling_size = [0, 50, 100, 300, 600]\n",
    "sort_by_time = [True, False]\n",
    "partition_ratio = [[0.5, 0.25, 0.25], [0.6, 0.2, 0.2], [0.8, 0.1, 0.1]]\n",
    "\n",
    "\n",
    "\n",
    "# training_method = ['active_learning']\n",
    "# balanced = [True]\n",
    "# sampling_size = [10]\n",
    "# sort_by_time = [False]\n",
    "# partition_ratio = [[0.8, 0.1, 0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5848d2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "model_result_df = pd.DataFrame()\n",
    "index = 1\n",
    "model_name = \"SVC, KNN, Decision Tree, Random Forest, AdaBoost\"\n",
    "for tm in training_method:\n",
    "    for b in balanced:\n",
    "        for ss in sampling_size:\n",
    "            for t in sort_by_time:\n",
    "                for r in partition_ratio:\n",
    "                    print(index)\n",
    "                    model_output = trial(df, model_name, tm, b, ss, t, r)\n",
    "                    if index == 0:\n",
    "                        model_result_df = pd.DataFrame(model_output, index=index)\n",
    "                    else:\n",
    "                        model_result_df = model_result_df.append(pd.DataFrame([model_output],index=[index]))\n",
    "                    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bce332de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_names</th>\n",
       "      <th>training_method</th>\n",
       "      <th>balance</th>\n",
       "      <th>sampling_size</th>\n",
       "      <th>sort_by_time</th>\n",
       "      <th>partition_ratio</th>\n",
       "      <th>seed_size</th>\n",
       "      <th>unlabeled_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>recall_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>207</td>\n",
       "      <td>102</td>\n",
       "      <td>108</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.6, 0.2, 0.2]</td>\n",
       "      <td>249</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.8, 0.1, 0.1]</td>\n",
       "      <td>333</td>\n",
       "      <td>39</td>\n",
       "      <td>45</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>207</td>\n",
       "      <td>102</td>\n",
       "      <td>108</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.6, 0.2, 0.2]</td>\n",
       "      <td>249</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        model_names  training_method  balance  \\\n",
       "1  SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling     True   \n",
       "2  SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling     True   \n",
       "3  SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling     True   \n",
       "4  SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling     True   \n",
       "5  SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling     True   \n",
       "\n",
       "   sampling_size  sort_by_time    partition_ratio  seed_size  unlabeled_size  \\\n",
       "1              0          True  [0.5, 0.25, 0.25]        207             102   \n",
       "2              0          True    [0.6, 0.2, 0.2]        249              81   \n",
       "3              0          True    [0.8, 0.1, 0.1]        333              39   \n",
       "4              0         False  [0.5, 0.25, 0.25]        207             102   \n",
       "5              0         False    [0.6, 0.2, 0.2]        249              81   \n",
       "\n",
       "   test_size  accuracy  f1_micro  f1_macro  f1_weighted  precision_micro  \\\n",
       "1        108     0.519     0.519     0.499        0.499            0.519   \n",
       "2         87     0.598     0.598     0.581        0.581            0.598   \n",
       "3         45     0.533     0.533     0.482        0.482            0.533   \n",
       "4        108     0.528     0.528     0.499        0.499            0.528   \n",
       "5         87     0.540     0.540     0.525        0.525            0.540   \n",
       "\n",
       "   precision_macro  precision_weighted  recall_micro  recall_macro  \\\n",
       "1            0.503               0.503         0.519         0.519   \n",
       "2            0.586               0.586         0.598         0.598   \n",
       "3            0.572               0.572         0.533         0.533   \n",
       "4            0.489               0.489         0.528         0.528   \n",
       "5            0.522               0.522         0.540         0.540   \n",
       "\n",
       "   recall_weighted  \n",
       "1            0.519  \n",
       "2            0.598  \n",
       "3            0.533  \n",
       "4            0.528  \n",
       "5            0.540  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c583f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result_df.to_csv('sentiment_committee_model_result.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3340e961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 19)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75d77f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_names</th>\n",
       "      <th>training_method</th>\n",
       "      <th>balance</th>\n",
       "      <th>sampling_size</th>\n",
       "      <th>sort_by_time</th>\n",
       "      <th>partition_ratio</th>\n",
       "      <th>seed_size</th>\n",
       "      <th>unlabeled_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>recall_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>207</td>\n",
       "      <td>102</td>\n",
       "      <td>108</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.6, 0.2, 0.2]</td>\n",
       "      <td>249</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.8, 0.1, 0.1]</td>\n",
       "      <td>333</td>\n",
       "      <td>39</td>\n",
       "      <td>45</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>207</td>\n",
       "      <td>102</td>\n",
       "      <td>108</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.6, 0.2, 0.2]</td>\n",
       "      <td>249</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.6, 0.2, 0.2]</td>\n",
       "      <td>4418</td>\n",
       "      <td>1471</td>\n",
       "      <td>1476</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.8, 0.1, 0.1]</td>\n",
       "      <td>5891</td>\n",
       "      <td>735</td>\n",
       "      <td>739</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>3682</td>\n",
       "      <td>1840</td>\n",
       "      <td>1843</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.6, 0.2, 0.2]</td>\n",
       "      <td>4418</td>\n",
       "      <td>1471</td>\n",
       "      <td>1476</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.8, 0.1, 0.1]</td>\n",
       "      <td>5891</td>\n",
       "      <td>735</td>\n",
       "      <td>739</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_names  training_method  \\\n",
       "1    SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling   \n",
       "2    SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling   \n",
       "3    SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling   \n",
       "4    SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling   \n",
       "5    SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling   \n",
       "..                                                ...              ...   \n",
       "116  SVC, KNN, Decision Tree, Random Forest, AdaBoost  active_learning   \n",
       "117  SVC, KNN, Decision Tree, Random Forest, AdaBoost  active_learning   \n",
       "118  SVC, KNN, Decision Tree, Random Forest, AdaBoost  active_learning   \n",
       "119  SVC, KNN, Decision Tree, Random Forest, AdaBoost  active_learning   \n",
       "120  SVC, KNN, Decision Tree, Random Forest, AdaBoost  active_learning   \n",
       "\n",
       "     balance  sampling_size  sort_by_time    partition_ratio  seed_size  \\\n",
       "1       True              0          True  [0.5, 0.25, 0.25]        207   \n",
       "2       True              0          True    [0.6, 0.2, 0.2]        249   \n",
       "3       True              0          True    [0.8, 0.1, 0.1]        333   \n",
       "4       True              0         False  [0.5, 0.25, 0.25]        207   \n",
       "5       True              0         False    [0.6, 0.2, 0.2]        249   \n",
       "..       ...            ...           ...                ...        ...   \n",
       "116    False            600          True    [0.6, 0.2, 0.2]       4418   \n",
       "117    False            600          True    [0.8, 0.1, 0.1]       5891   \n",
       "118    False            600         False  [0.5, 0.25, 0.25]       3682   \n",
       "119    False            600         False    [0.6, 0.2, 0.2]       4418   \n",
       "120    False            600         False    [0.8, 0.1, 0.1]       5891   \n",
       "\n",
       "     unlabeled_size  test_size  accuracy  f1_micro  f1_macro  f1_weighted  \\\n",
       "1               102        108     0.519     0.519     0.499        0.499   \n",
       "2                81         87     0.598     0.598     0.581        0.581   \n",
       "3                39         45     0.533     0.533     0.482        0.482   \n",
       "4               102        108     0.528     0.528     0.499        0.499   \n",
       "5                81         87     0.540     0.540     0.525        0.525   \n",
       "..              ...        ...       ...       ...       ...          ...   \n",
       "116            1471       1476     0.959     0.959     0.346        0.939   \n",
       "117             735        739     0.958     0.958     0.363        0.939   \n",
       "118            1840       1843     0.959     0.959     0.342        0.939   \n",
       "119            1471       1476     0.959     0.959     0.346        0.939   \n",
       "120             735        739     0.958     0.958     0.363        0.939   \n",
       "\n",
       "     precision_micro  precision_macro  precision_weighted  recall_micro  \\\n",
       "1              0.519            0.503               0.503         0.519   \n",
       "2              0.598            0.586               0.586         0.598   \n",
       "3              0.533            0.572               0.572         0.533   \n",
       "4              0.528            0.489               0.489         0.528   \n",
       "5              0.540            0.522               0.522         0.540   \n",
       "..               ...              ...                 ...           ...   \n",
       "116            0.959            0.653               0.941         0.959   \n",
       "117            0.958            0.653               0.940         0.958   \n",
       "118            0.959            0.653               0.941         0.959   \n",
       "119            0.959            0.653               0.941         0.959   \n",
       "120            0.958            0.653               0.940         0.958   \n",
       "\n",
       "     recall_macro  recall_weighted  \n",
       "1           0.519            0.519  \n",
       "2           0.598            0.598  \n",
       "3           0.533            0.533  \n",
       "4           0.528            0.528  \n",
       "5           0.540            0.540  \n",
       "..            ...              ...  \n",
       "116         0.343            0.959  \n",
       "117         0.353            0.958  \n",
       "118         0.341            0.959  \n",
       "119         0.343            0.959  \n",
       "120         0.353            0.958  \n",
       "\n",
       "[120 rows x 19 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d908a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc5ac57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2829093d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00794f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a88e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064764de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54fd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8164b135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa623de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade2f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
