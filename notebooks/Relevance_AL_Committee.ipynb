{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e04c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import unidecode\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4226012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022 = pd.read_csv('../data/tweet_data_2022.csv')\n",
    "df_2023 = pd.read_csv('../data/tweet_data_2023.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6665c20",
   "metadata": {},
   "source": [
    "### Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b6b2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_number = 3\n",
    "random_state = 42\n",
    "categories = ['Bucket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09f8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_bucket(bucket):\n",
    "    if ((bucket == '1.0') | (bucket == '1')):\n",
    "        return '1'\n",
    "    elif ((bucket == '2') | (bucket == '3') | (bucket == '2.0') | (bucket == '3.0')):\n",
    "        return '2 or 3'\n",
    "    else:\n",
    "        return bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3034b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if type(text) == np.float:\n",
    "        return \"\"\n",
    "    temp = text.lower() # to lower case\n",
    "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp) # remove @s\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp) # remove hashtags\n",
    "    temp = re.sub(r'http\\S+', '', temp) # remove links\n",
    "    temp = re.sub(r\"www.\\S+\", \"\", temp) # remove links\n",
    "    temp = re.sub(r'\\n|[^a-zA-Z]', ' ', temp) # remove punctuation\n",
    "    temp = temp.replace(\"\\n\", \" \").split()\n",
    "    temp = [w for w in temp if not w in stopwords_] # remove stopwords\n",
    "    temp = [w for w in temp if not w.isdigit()] # remove numbers\n",
    "    temp = [unidecode.unidecode(w) for w in temp] # turn non-enlish letters to english letters\n",
    "    temp = \" \".join(word for word in temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04826dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(df, ratio, time):\n",
    "    #partiton\n",
    "    if time:\n",
    "        df.sort_values(by=['date'], inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "    df_rows = df.shape[0]\n",
    "    seed_num = math.floor(df_rows * ratio[0])\n",
    "    seed = df[:seed_num]\n",
    "    unlabeled_num = seed_num + (math.floor(df_rows * ratio[1]))\n",
    "    unlabeled = df[seed_num:unlabeled_num]\n",
    "    test = df[unlabeled_num:]\n",
    "    return seed, unlabeled, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d091725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(seed):\n",
    "    cv = 5\n",
    "    train, test = train_test_split(seed, random_state=random_state, test_size=0.2, shuffle=True)\n",
    "    X_train, X_test, Y_train, Y_test = train[['text_cleaned']], test[['text_cleaned']], train[['Bucket']], test[['Bucket']]\n",
    "    #Wrap in ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tf\", CountVectorizer(stop_words=stopwords_), 'text_cleaned'),\n",
    "            (\"tfidf\", TfidfVectorizer(stop_words=stopwords_), 'text_cleaned')]\n",
    "    )\n",
    "    #Define the model\n",
    "    model_lst = [\n",
    "                SVC(),\n",
    "                KNeighborsClassifier(),\n",
    "                DecisionTreeClassifier(),\n",
    "                RandomForestClassifier(),\n",
    "                AdaBoostClassifier(),\n",
    "            ]\n",
    "    \n",
    "    pl_preds = []\n",
    "    for model in model_lst:\n",
    "        #Build the pipeline\n",
    "        pipeline = Pipeline([\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('clf', OneVsRestClassifier(model, n_jobs=1)),\n",
    "                ])\n",
    "        #Train the model\n",
    "        pipeline.fit(X_train, Y_train)\n",
    "        # compute the testing accuracy\n",
    "        prediction = pipeline.predict(pd.DataFrame(X_test))\n",
    "        pl_preds.append([pipeline, prediction])\n",
    "        \n",
    "    #Saves all the model pipelines\n",
    "    pipelines = [x[0] for x in pl_preds]\n",
    "    #Saves all the model predictions\n",
    "    all_preds = np.array([x[1] for x in pl_preds]).transpose()\n",
    "    #Find the mode in all preds\n",
    "    final_preds = [mode(i) for i in all_preds]\n",
    "    accuracy = accuracy_score(Y_test,final_preds)\n",
    "    return pipelines, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "836d90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(lst):\n",
    "    unique_num = list(set(lst))\n",
    "    entropy = 0\n",
    "    for i in range(len(unique_num)):\n",
    "        label = unique_num[i]\n",
    "        prob = sum(np.array(lst) == label)/len(lst)\n",
    "        entropy += prob * math.log2(1/prob)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39aef465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_unlabeled(pipelines, unlabeled):\n",
    "    unlabeled_x = unlabeled[['text_cleaned']]\n",
    "    unlabeled_y = unlabeled[['Bucket']]\n",
    "    all_preds = np.array([pl.predict(unlabeled_x) for pl in pipelines]).transpose()\n",
    "    unlabeled['all_preds'] = list(all_preds)\n",
    "    unlabeled['entropy'] = unlabeled['all_preds'].apply(calc_entropy)\n",
    "    unlabeled.sort_values(by=['entropy'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4a29a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learning(pipelines, seed, unlabeled, instances):\n",
    "    # Sort the unlabeled data based on informativeness level\n",
    "    choose_unlabeled(pipelines, unlabeled)\n",
    "    # Update the unlabeled data and the info_data\n",
    "    info_data, unlabeled = unlabeled.iloc[:instances], unlabeled.iloc[instances:]\n",
    "    # Add selected data to the training set\n",
    "    seed = pd.concat([seed, info_data[['date', 'text', 'Bucket', 'text_cleaned']]])\n",
    "    pipelines, accuracy = train_model(seed)\n",
    "    return pipelines, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03fc5bf",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca671fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_stopwords = stopwords.words('english')\n",
    "additional_stopwords = ['none']\n",
    "original_stopwords.extend(additional_stopwords)\n",
    "stopwords_ = set(original_stopwords)\n",
    "\n",
    "#Selects only the tweets about China\n",
    "df = df_2022[df_2022['country']=='China']\n",
    "df = df[['date', 'text', 'id', 'Bucket', 'SentimentScore']]\n",
    "\n",
    "#Shuffle the data\n",
    "df = df.sample(frac=1, replace=False, random_state=1) \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#Standardized the bucket label\n",
    "df['Bucket'] = df['Bucket'].apply(standardize_bucket)\n",
    "#Remove tweets that are in both buckets\n",
    "df_bucket_count = pd.DataFrame(df.groupby('id')['Bucket'].nunique())\n",
    "df_bucket_count.reset_index(inplace=True)\n",
    "df_bucket_count.columns = ['tweet_id', 'bucket_num']\n",
    "df = df.merge(df_bucket_count, left_on='id', right_on='tweet_id')\n",
    "df = df[df['bucket_num'] == 1]\n",
    "#Remove tweets without a bucket (null)\n",
    "df = df[(df['Bucket'] == '1') | (df['Bucket'] == '2 or 3')]\n",
    "#Remove duplicates\n",
    "df = df.drop_duplicates(subset=['id']).reset_index(drop=True)\n",
    "df = df[['date', 'text', 'Bucket']]\n",
    "df[\"text_cleaned\"] = [clean_text(t) for t in df[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e7f3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(df, model_names, training_method, balance, sampling_size, sort_by_time, partition_ratio):\n",
    "    output = {}\n",
    "    output['model_names'] = model_names\n",
    "    output['training_method'] = training_method #random_sampling, active_learning\n",
    "    output['balance'] = balance\n",
    "    output['sampling_size'] = sampling_size\n",
    "    output['sort_by_time'] = sort_by_time\n",
    "    output['partition_ratio'] = partition_ratio\n",
    "    accuracy_lst, f1_lst, precision_lst, recall_lst, specificity_lst = [], [], [], [], []\n",
    "    \n",
    "    for i in range(5):\n",
    "        # 1. Balance dataset \n",
    "        df_1, df_2_3 = df[df.Bucket=='1'], df[df.Bucket=='2 or 3']\n",
    "        df_lst = [df_1, df_2_3]\n",
    "\n",
    "        # 1.1 Balance the label distribution  (50% Bucket 1 vs. 50% Non-Bucket 1)\n",
    "        if balance:\n",
    "            sample_size = min(df_1.shape[0], df_2_3.shape[0])\n",
    "            if df_1.shape[0] > sample_size:\n",
    "                df_1 = resample(df_1, replace=False, n_samples=sample_size, random_state=random_state)\n",
    "            if df_2_3.shape[0] > sample_size:\n",
    "                df_2_3 = resample(df_2_3, replace=False, n_samples=sample_size, random_state=random_state)\n",
    "\n",
    "        # 1.2 Keep the natural label distribution\n",
    "        seed_1, unlabeled_1, test_1 = partition_data(df_1, partition_ratio, sort_by_time)\n",
    "        seed_2_3, unlabeled_2_3, test_2_3 = partition_data(df_2_3, partition_ratio, sort_by_time)\n",
    "        seed, unlabeled, test = pd.concat([seed_1, seed_2_3]), pd.concat([unlabeled_1, unlabeled_2_3]), pd.concat([test_1, test_2_3])\n",
    "        output['seed_size'], output['unlabeled_size'], output['test_size'] = seed.shape[0], unlabeled.shape[0], test.shape[0]\n",
    "\n",
    "        initial_seed = seed.copy()\n",
    "        initial_unlabeled = unlabeled.copy()\n",
    "\n",
    "        # 2. Train the model\n",
    "        initial_pipelines, initial_accuracy = train_model(initial_seed)\n",
    "\n",
    "        # 3. Active Learning\n",
    "        if sampling_size == 0:\n",
    "            pipelines, accuracy = initial_pipelines, initial_accuracy\n",
    "\n",
    "        # 3.1 Initial Model + Random Sampling\n",
    "        elif training_method == 'random_sampling':\n",
    "            if initial_unlabeled.shape[0] >= sampling_size:\n",
    "                sample_unlabeled = initial_unlabeled.sample(n=sampling_size, replace=False, random_state=i)\n",
    "            else:\n",
    "                sample_unlabeled = initial_unlabeled.sample(n=sampling_size, replace=True, random_state=i)\n",
    "            seed_and_sample_unlabeled_df = pd.concat([initial_seed, sample_unlabeled])\n",
    "            pipelines, accuracy = train_model(seed_and_sample_unlabeled_df)\n",
    "\n",
    "        # 3.2 Initial Model + Active Learning\n",
    "        else:\n",
    "            pipelines, accuracy = active_learning(initial_pipelines, initial_seed, initial_unlabeled, sampling_size)\n",
    "\n",
    "        # 4. Report Model Accuracy\n",
    "        X_test, Y_test = test[['text_cleaned']], test[['Bucket']]\n",
    "\n",
    "\n",
    "        pl_preds = []\n",
    "        for pl in pipelines:\n",
    "            # compute the testing accuracy\n",
    "            prediction = pl.predict(pd.DataFrame(X_test))\n",
    "            pl_preds.append([pl, prediction])\n",
    "\n",
    "        #Saves all the model predictions\n",
    "        all_preds = np.array([x[1] for x in pl_preds]).transpose()\n",
    "        #Find the mode in all preds\n",
    "        prediction = [mode(i) for i in all_preds]\n",
    "        accuracy = round(accuracy_score(Y_test, prediction), round_number)\n",
    "        f1 = round(f1_score(np.array(Y_test), prediction, pos_label='1'), round_number)\n",
    "        precision = round(precision_score(np.array(Y_test), prediction, pos_label='1', average='binary'), round_number)\n",
    "        recall = round(recall_score(np.array(Y_test), prediction, pos_label='1', average='binary'), round_number)\n",
    "        specificity = round(recall_score(np.array(Y_test), prediction, pos_label='2 or 3', average='binary'), round_number)\n",
    "        \n",
    "        accuracy_lst.append(accuracy)\n",
    "        f1_lst.append(f1)\n",
    "        precision_lst.append(precision) \n",
    "        recall_lst.append(recall) \n",
    "        specificity_lst.append(specificity) \n",
    "    \n",
    "    output['accuracy'] = np.mean(accuracy_lst)\n",
    "    output['f1_score'] = np.mean(f1_lst)\n",
    "    output['precision'] = np.mean(precision_lst)\n",
    "    output['recall'] = np.mean(recall_lst)\n",
    "    output['specificity'] = np.mean(specificity_lst)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4063903",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_method = ['random_sampling', 'active_learning']\n",
    "balanced = [True, False]\n",
    "sampling_size = [0, 200, 400, 600]\n",
    "sort_by_time = [True, False]\n",
    "partition_ratio = [[0.1, 0.45, 0.45], [0.5, 0.25, 0.25], [0.9, 0.05, 0.05]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5848d2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "model_result_df = pd.DataFrame()\n",
    "index = 1\n",
    "model_name = \"SVC, KNN, Decision Tree, Random Forest, AdaBoost\"\n",
    "for tm in training_method:\n",
    "    for b in balanced:\n",
    "        for ss in sampling_size:\n",
    "            for t in sort_by_time:\n",
    "                for r in partition_ratio:\n",
    "                    print(index)\n",
    "                    model_output = trial(df, model_name, tm, b, ss, t, r)\n",
    "                    if index == 0:\n",
    "                        model_result_df = pd.DataFrame(model_output, index=index)\n",
    "                    else:\n",
    "                        model_result_df = model_result_df.append(pd.DataFrame([model_output],index=[index]))\n",
    "                    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bce332de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_names</th>\n",
       "      <th>training_method</th>\n",
       "      <th>balance</th>\n",
       "      <th>sampling_size</th>\n",
       "      <th>sort_by_time</th>\n",
       "      <th>partition_ratio</th>\n",
       "      <th>seed_size</th>\n",
       "      <th>unlabeled_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.1, 0.45, 0.45]</td>\n",
       "      <td>412</td>\n",
       "      <td>1854</td>\n",
       "      <td>1858</td>\n",
       "      <td>0.5702</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>0.5778</td>\n",
       "      <td>0.5196</td>\n",
       "      <td>0.6204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>2062</td>\n",
       "      <td>1030</td>\n",
       "      <td>1032</td>\n",
       "      <td>0.7346</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.7190</td>\n",
       "      <td>0.7712</td>\n",
       "      <td>0.6980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.9, 0.05, 0.05]</td>\n",
       "      <td>3710</td>\n",
       "      <td>206</td>\n",
       "      <td>208</td>\n",
       "      <td>0.7644</td>\n",
       "      <td>0.7846</td>\n",
       "      <td>0.7232</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>0.6712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.1, 0.45, 0.45]</td>\n",
       "      <td>412</td>\n",
       "      <td>1854</td>\n",
       "      <td>1858</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.6462</td>\n",
       "      <td>0.7654</td>\n",
       "      <td>0.5596</td>\n",
       "      <td>0.8286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>2062</td>\n",
       "      <td>1030</td>\n",
       "      <td>1032</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.7434</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>0.8116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>5073</td>\n",
       "      <td>2536</td>\n",
       "      <td>2538</td>\n",
       "      <td>0.8314</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.8284</td>\n",
       "      <td>0.9942</td>\n",
       "      <td>0.1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.9, 0.05, 0.05]</td>\n",
       "      <td>9131</td>\n",
       "      <td>507</td>\n",
       "      <td>509</td>\n",
       "      <td>0.8230</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8190</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.1440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.1, 0.45, 0.45]</td>\n",
       "      <td>1014</td>\n",
       "      <td>4565</td>\n",
       "      <td>4568</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.8946</td>\n",
       "      <td>0.8220</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.1670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>5073</td>\n",
       "      <td>2536</td>\n",
       "      <td>2538</td>\n",
       "      <td>0.8446</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.8470</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SVC, KNN, Decision Tree, Random Forest, AdaBoost</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.9, 0.05, 0.05]</td>\n",
       "      <td>9131</td>\n",
       "      <td>507</td>\n",
       "      <td>509</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.9106</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.2884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         model_names  training_method  \\\n",
       "1   SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling   \n",
       "2   SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling   \n",
       "3   SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling   \n",
       "4   SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling   \n",
       "5   SVC, KNN, Decision Tree, Random Forest, AdaBoost  random_sampling   \n",
       "..                                               ...              ...   \n",
       "92  SVC, KNN, Decision Tree, Random Forest, AdaBoost  active_learning   \n",
       "93  SVC, KNN, Decision Tree, Random Forest, AdaBoost  active_learning   \n",
       "94  SVC, KNN, Decision Tree, Random Forest, AdaBoost  active_learning   \n",
       "95  SVC, KNN, Decision Tree, Random Forest, AdaBoost  active_learning   \n",
       "96  SVC, KNN, Decision Tree, Random Forest, AdaBoost  active_learning   \n",
       "\n",
       "    balance  sampling_size  sort_by_time    partition_ratio  seed_size  \\\n",
       "1      True              0          True  [0.1, 0.45, 0.45]        412   \n",
       "2      True              0          True  [0.5, 0.25, 0.25]       2062   \n",
       "3      True              0          True  [0.9, 0.05, 0.05]       3710   \n",
       "4      True              0         False  [0.1, 0.45, 0.45]        412   \n",
       "5      True              0         False  [0.5, 0.25, 0.25]       2062   \n",
       "..      ...            ...           ...                ...        ...   \n",
       "92    False            600          True  [0.5, 0.25, 0.25]       5073   \n",
       "93    False            600          True  [0.9, 0.05, 0.05]       9131   \n",
       "94    False            600         False  [0.1, 0.45, 0.45]       1014   \n",
       "95    False            600         False  [0.5, 0.25, 0.25]       5073   \n",
       "96    False            600         False  [0.9, 0.05, 0.05]       9131   \n",
       "\n",
       "    unlabeled_size  test_size  accuracy  f1_score  precision  recall  \\\n",
       "1             1854       1858    0.5702    0.5470     0.5778  0.5196   \n",
       "2             1030       1032    0.7346    0.7440     0.7190  0.7712   \n",
       "3              206        208    0.7644    0.7846     0.7232  0.8578   \n",
       "4             1854       1858    0.6940    0.6462     0.7654  0.5596   \n",
       "5             1030       1032    0.7576    0.7434     0.7886  0.7030   \n",
       "..             ...        ...       ...       ...        ...     ...   \n",
       "92            2536       2538    0.8314    0.9036     0.8284  0.9942   \n",
       "93             507        509    0.8230    0.9000     0.8190  0.9980   \n",
       "94            4565       4568    0.8160    0.8946     0.8220  0.9814   \n",
       "95            2536       2538    0.8446    0.9098     0.8470  0.9824   \n",
       "96             507        509    0.8462    0.9106     0.8440  0.9892   \n",
       "\n",
       "    specificity  \n",
       "1        0.6204  \n",
       "2        0.6980  \n",
       "3        0.6712  \n",
       "4        0.8286  \n",
       "5        0.8116  \n",
       "..          ...  \n",
       "92       0.1930  \n",
       "93       0.1440  \n",
       "94       0.1670  \n",
       "95       0.3050  \n",
       "96       0.2884  \n",
       "\n",
       "[96 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c583f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result_df.to_csv('bucket_committee_model_result.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d908a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd8b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaeb2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db8c66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf644f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c54863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4b042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22e2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66099f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df87846b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
