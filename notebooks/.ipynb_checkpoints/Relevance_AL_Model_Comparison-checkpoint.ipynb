{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e04c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "import unidecode\n",
    "from sklearn.utils import resample\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4226012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022 = pd.read_csv('../data/tweet_data_2022.csv')\n",
    "df_2023 = pd.read_csv('../data/tweet_data_2023.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6665c20",
   "metadata": {},
   "source": [
    "### Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b6b2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_number = 3\n",
    "random_state = 42\n",
    "categories = ['Bucket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09f8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_bucket(bucket):\n",
    "    if ((bucket == '1.0') | (bucket == '1')):\n",
    "        return '1'\n",
    "    elif ((bucket == '2') | (bucket == '3') | (bucket == '2.0') | (bucket == '3.0')):\n",
    "        return '2 or 3'\n",
    "    else:\n",
    "        return bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3034b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if type(text) == np.float:\n",
    "        return \"\"\n",
    "    temp = text.lower() # to lower case\n",
    "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp) # remove @s\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp) # remove hashtags\n",
    "    temp = re.sub(r'http\\S+', '', temp) # remove links\n",
    "    temp = re.sub(r\"www.\\S+\", \"\", temp) # remove links\n",
    "    temp = re.sub(r'\\n|[^a-zA-Z]', ' ', temp) # remove punctuation\n",
    "    temp = temp.replace(\"\\n\", \" \").split()\n",
    "    temp = [w for w in temp if not w in stopwords_] # remove stopwords\n",
    "    temp = [w for w in temp if not w.isdigit()] # remove numbers\n",
    "    temp = [unidecode.unidecode(w) for w in temp] # turn non-enlish letters to english letters\n",
    "    temp = \" \".join(word for word in temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04826dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(df, ratio, time):\n",
    "    #partiton\n",
    "    if time:\n",
    "        df.sort_values(by=['date'], inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "    df_rows = df.shape[0]\n",
    "    seed_num = math.floor(df_rows * ratio[0])\n",
    "    seed = df[:seed_num]\n",
    "    unlabeled_num = seed_num + (math.floor(df_rows * ratio[1]))\n",
    "    unlabeled = df[seed_num:unlabeled_num]\n",
    "    test = df[unlabeled_num:]\n",
    "    return seed, unlabeled, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d091725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(seed, model_index):\n",
    "    cv = 5\n",
    "    train, test = train_test_split(seed, random_state=random_state, test_size=0.2, shuffle=True)\n",
    "    X_train, X_test, Y_train, Y_test = train[['text_cleaned']], test[['text_cleaned']], train[['Bucket']], test[['Bucket']]\n",
    "    #Wrap in ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tf\", CountVectorizer(stop_words=stopwords_), 'text_cleaned'),\n",
    "            (\"tfidf\", TfidfVectorizer(stop_words=stopwords_), 'text_cleaned')]\n",
    "    )\n",
    "    #Define the model\n",
    "    model_lst = [\n",
    "#                  SVC(kernel='rbf', probability=True, random_state=random_state), #SVC RBF\n",
    "#                  SVC(kernel='poly', probability=True, degree=4, random_state=random_state), #SVC Poly\n",
    "                 BernoulliNB(fit_prior=True, class_prior=None), #Naive Bayes\n",
    "                 RandomForestClassifier(random_state=random_state), #Random Forest\n",
    "                 LogisticRegression(solver='sag', random_state=random_state), #Logistic Regression (Ridge)\n",
    "                 LogisticRegression(C=1, penalty='l1', solver='liblinear', random_state=random_state), #Logistic Regression (Lasso)\n",
    "            ]\n",
    "    model = model_lst[model_index]\n",
    "    \n",
    "    #Build the pipeline\n",
    "    pipeline = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('clf', OneVsRestClassifier(model, n_jobs=1)),\n",
    "            ])\n",
    "    #Train the model\n",
    "    pipeline.fit(X_train, Y_train)\n",
    "    # compute the testing accuracy\n",
    "    prediction = pipeline.predict(pd.DataFrame(X_test))\n",
    "    #Cross Validation\n",
    "    val_score = round(np.mean(cross_val_score(pipeline, X_test, Y_test, cv=cv)), round_number)\n",
    "    return pipeline, val_scor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "836d90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(x):\n",
    "    entropy = 0\n",
    "    for i in x:\n",
    "        entropy += i * math.log2(1/i)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6e4acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39aef465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_unlabeled(pipeline, unlabeled):\n",
    "    unlabeled_x = unlabeled[['text_cleaned']]\n",
    "    unlabeled_y = unlabeled[['Bucket']]\n",
    "    prob = pipeline.predict_proba(unlabeled_x)\n",
    "    unlabeled['prob'] = list(prob)\n",
    "    unlabeled['entropy'] = unlabeled['prob'].apply(calc_entropy)\n",
    "    unlabeled.sort_values(by=['entropy'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4a29a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learning(pipeline, seed, unlabeled, instances, model_index):\n",
    "    # Sort the unlabeled data based on informativeness level\n",
    "    choose_unlabeled(pipeline, unlabeled)\n",
    "    # Update the unlabeled data and the info_data\n",
    "    info_data, unlabeled = unlabeled.iloc[:instances], unlabeled.iloc[instances:]\n",
    "    # Add selected data to the training set\n",
    "    seed = pd.concat([seed, info_data[['date', 'text', 'Bucket', 'text_cleaned']]])\n",
    "    pipeline, validation_score = train_model(seed, model_index)\n",
    "    return pipeline, validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03fc5bf",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca671fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_stopwords = stopwords.words('english')\n",
    "additional_stopwords = ['none']\n",
    "original_stopwords.extend(additional_stopwords)\n",
    "stopwords_ = set(original_stopwords)\n",
    "\n",
    "#Selects only the tweets about China\n",
    "df = df_2022[df_2022['country']=='China']\n",
    "df = df[['date', 'text', 'id', 'Bucket', 'SentimentScore']]\n",
    "\n",
    "#Shuffle the data\n",
    "df = df.sample(frac=1, replace=False, random_state=1) \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#Standardized the bucket label\n",
    "df['Bucket'] = df['Bucket'].apply(standardize_bucket)\n",
    "#Remove tweets that are in both buckets\n",
    "df_bucket_count = pd.DataFrame(df.groupby('id')['Bucket'].nunique())\n",
    "df_bucket_count.reset_index(inplace=True)\n",
    "df_bucket_count.columns = ['tweet_id', 'bucket_num']\n",
    "df = df.merge(df_bucket_count, left_on='id', right_on='tweet_id')\n",
    "df = df[df['bucket_num'] == 1]\n",
    "#Remove tweets without a bucket (null)\n",
    "df = df[(df['Bucket'] == '1') | (df['Bucket'] == '2 or 3')]\n",
    "#Remove duplicates\n",
    "df = df.drop_duplicates(subset=['id']).reset_index(drop=True)\n",
    "df = df[['date', 'text', 'Bucket']]\n",
    "df[\"text_cleaned\"] = [clean_text(t) for t in df[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e7f3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(df, model_name, model_index, training_method, balance, sampling_size, sort_by_time, partition_ratio):\n",
    "    output = {}\n",
    "    output['model_name'] = model_name\n",
    "    output['training_method'] = training_method #random_sampling, active_learning\n",
    "    output['balance'] = balance\n",
    "    output['sampling_size'] = sampling_size\n",
    "    output['sort_by_time'] = sort_by_time\n",
    "    output['partition_ratio'] = partition_ratio\n",
    "        \n",
    "    # 1. Balance dataset \n",
    "    df_1, df_2_3 = df[df.Bucket=='1'], df[df.Bucket=='2 or 3']\n",
    "    df_lst = [df_1, df_2_3]\n",
    "    \n",
    "    # 1.1 Balance the label distribution  (50% Bucket 1 vs. 50% Non-Bucket 1)\n",
    "    if balance:\n",
    "        sample_size = min(df_1.shape[0], df_2_3.shape[0])\n",
    "        if df_1.shape[0] > sample_size:\n",
    "            df_1 = resample(df_1, replace=False, n_samples=sample_size, random_state=random_state)\n",
    "        if df_2_3.shape[0] > sample_size:\n",
    "            df_2_3 = resample(df_2_3, replace=False, n_samples=sample_size, random_state=random_state)\n",
    "\n",
    "    # 1.2 Keep the natural label distribution\n",
    "    seed_1, unlabeled_1, test_1 = partition_data(df_1, partition_ratio, sort_by_time)\n",
    "    seed_2_3, unlabeled_2_3, test_2_3 = partition_data(df_2_3, partition_ratio, sort_by_time)\n",
    "    seed, unlabeled, test = pd.concat([seed_1, seed_2_3]), pd.concat([unlabeled_1, unlabeled_2_3]), pd.concat([test_1, test_2_3])\n",
    "    output['seed_size'], output['unlabeled_size'], output['test_size'] = seed.shape[0], unlabeled.shape[0], test.shape[0]\n",
    "    \n",
    "    initial_seed = seed.copy()\n",
    "    initial_unlabeled = unlabeled.copy()\n",
    "    \n",
    "    # 2. Train the model\n",
    "    initial_pipeline, initial_val_score = train_model(initial_seed, model_index)\n",
    "    \n",
    "    # 3. Active Learning\n",
    "    if sampling_size == 0:\n",
    "        pipeline, val_score = initial_pipeline, initial_val_score\n",
    "        \n",
    "    # 3.1 Initial Model + Random Sampling\n",
    "    elif training_method == 'random_sampling':\n",
    "        if initial_unlabeled.shape[0] >= sampling_size:\n",
    "            sample_unlabeled = initial_unlabeled.sample(n=sampling_size, replace=False, random_state=random_state)\n",
    "        else:\n",
    "            sample_unlabeled = initial_unlabeled.sample(n=sampling_size, replace=True, random_state=random_state)\n",
    "        seed_and_sample_unlabeled_df = pd.concat([initial_seed, sample_unlabeled])\n",
    "        pipeline, val_score = train_model(seed_and_sample_unlabeled_df, model_index)\n",
    "        \n",
    "    # 3.2 Initial Model + Active Learning\n",
    "    else:\n",
    "        pipeline, val_score = active_learning(initial_pipeline, initial_seed, initial_unlabeled, sampling_size, model_index)\n",
    "\n",
    "    # 4. Report Model Accuracy\n",
    "    X_test, Y_test = test[['text_cleaned']], test[['Bucket']]\n",
    "    prediction = pipeline.predict(pd.DataFrame(X_test))\n",
    "    accuracy = round(accuracy_score(Y_test, prediction), round_number)\n",
    "    f1 = round(f1_score(np.array(Y_test), prediction, pos_label='1'), round_number)\n",
    "    precision = round(precision_score(np.array(Y_test), prediction, pos_label='1', average='binary'), round_number)\n",
    "    recall = round(recall_score(np.array(Y_test), prediction, pos_label='1', average='binary'), round_number)\n",
    "    specificity = round(recall_score(np.array(Y_test), prediction, pos_label='2 or 3', average='binary'), round_number)\n",
    "    output['val_score'] = val_score\n",
    "    output['accuracy'] = accuracy\n",
    "    output['f1_score'] = f1\n",
    "    output['precision'] = precision\n",
    "    output['recall'] = recall\n",
    "    output['specificity'] = specificity\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4063903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = ['SVC RBF', 'SVC Poly', 'Bernoulli Naive Bayes', 'Random Forest Classifier', \n",
    "#               'Logistic Regression', 'Lasso', 'Ridge']\n",
    "model_name = ['Bernoulli Naive Bayes', 'Random Forest Classifier', 'Logistic Regression (Ridge)', 'Logistic Regression (Lasso)']\n",
    "training_method = ['random_sampling', 'active_learning']\n",
    "balanced = [True, False]\n",
    "sampling_size = [0, 50, 100, 300, 600]\n",
    "sort_by_time = [True, False]\n",
    "partition_ratio = [[0.5, 0.25, 0.25], [0.6, 0.2, 0.2], [0.8, 0.1, 0.1]]\n",
    "\n",
    "\n",
    "# model_name = ['Bernoulli Naive Bayes', 'Random Forest Classifier', 'Logistic Regression (Ridge)', 'Logistic Regression (Lasso)']\n",
    "# training_method = ['active_learning']\n",
    "# balanced = [True]\n",
    "# sampling_size = [10]\n",
    "# sort_by_time = [False]\n",
    "# partition_ratio = [[0.8, 0.1, 0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5848d2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Bernoulli Naive Bayes\n",
      "2\n",
      "Bernoulli Naive Bayes\n",
      "3\n",
      "Bernoulli Naive Bayes\n",
      "4\n",
      "Bernoulli Naive Bayes\n",
      "5\n",
      "Bernoulli Naive Bayes\n",
      "6\n",
      "Bernoulli Naive Bayes\n",
      "7\n",
      "Bernoulli Naive Bayes\n",
      "8\n",
      "Bernoulli Naive Bayes\n",
      "9\n",
      "Bernoulli Naive Bayes\n",
      "10\n",
      "Bernoulli Naive Bayes\n",
      "11\n",
      "Bernoulli Naive Bayes\n",
      "12\n",
      "Bernoulli Naive Bayes\n",
      "13\n",
      "Bernoulli Naive Bayes\n",
      "14\n",
      "Bernoulli Naive Bayes\n",
      "15\n",
      "Bernoulli Naive Bayes\n",
      "16\n",
      "Bernoulli Naive Bayes\n",
      "17\n",
      "Bernoulli Naive Bayes\n",
      "18\n",
      "Bernoulli Naive Bayes\n",
      "19\n",
      "Bernoulli Naive Bayes\n",
      "20\n",
      "Bernoulli Naive Bayes\n",
      "21\n",
      "Bernoulli Naive Bayes\n",
      "22\n",
      "Bernoulli Naive Bayes\n",
      "23\n",
      "Bernoulli Naive Bayes\n",
      "24\n",
      "Bernoulli Naive Bayes\n",
      "25\n",
      "Bernoulli Naive Bayes\n",
      "26\n",
      "Bernoulli Naive Bayes\n",
      "27\n",
      "Bernoulli Naive Bayes\n",
      "28\n",
      "Bernoulli Naive Bayes\n",
      "29\n",
      "Bernoulli Naive Bayes\n",
      "30\n",
      "Bernoulli Naive Bayes\n",
      "31\n",
      "Bernoulli Naive Bayes\n",
      "32\n",
      "Bernoulli Naive Bayes\n",
      "33\n",
      "Bernoulli Naive Bayes\n",
      "34\n",
      "Bernoulli Naive Bayes\n",
      "35\n",
      "Bernoulli Naive Bayes\n",
      "36\n",
      "Bernoulli Naive Bayes\n",
      "37\n",
      "Bernoulli Naive Bayes\n",
      "38\n",
      "Bernoulli Naive Bayes\n",
      "39\n",
      "Bernoulli Naive Bayes\n",
      "40\n",
      "Bernoulli Naive Bayes\n",
      "41\n",
      "Bernoulli Naive Bayes\n",
      "42\n",
      "Bernoulli Naive Bayes\n",
      "43\n",
      "Bernoulli Naive Bayes\n",
      "44\n",
      "Bernoulli Naive Bayes\n",
      "45\n",
      "Bernoulli Naive Bayes\n",
      "46\n",
      "Bernoulli Naive Bayes\n",
      "47\n",
      "Bernoulli Naive Bayes\n",
      "48\n",
      "Bernoulli Naive Bayes\n",
      "49\n",
      "Bernoulli Naive Bayes\n",
      "50\n",
      "Bernoulli Naive Bayes\n",
      "51\n",
      "Bernoulli Naive Bayes\n",
      "52\n",
      "Bernoulli Naive Bayes\n",
      "53\n",
      "Bernoulli Naive Bayes\n",
      "54\n",
      "Bernoulli Naive Bayes\n",
      "55\n",
      "Bernoulli Naive Bayes\n",
      "56\n",
      "Bernoulli Naive Bayes\n",
      "57\n",
      "Bernoulli Naive Bayes\n",
      "58\n",
      "Bernoulli Naive Bayes\n",
      "59\n",
      "Bernoulli Naive Bayes\n",
      "60\n",
      "Bernoulli Naive Bayes\n",
      "61\n",
      "Bernoulli Naive Bayes\n",
      "62\n",
      "Bernoulli Naive Bayes\n",
      "63\n",
      "Bernoulli Naive Bayes\n",
      "64\n",
      "Bernoulli Naive Bayes\n",
      "65\n",
      "Bernoulli Naive Bayes\n",
      "66\n",
      "Bernoulli Naive Bayes\n",
      "67\n",
      "Bernoulli Naive Bayes\n",
      "68\n",
      "Bernoulli Naive Bayes\n",
      "69\n",
      "Bernoulli Naive Bayes\n",
      "70\n",
      "Bernoulli Naive Bayes\n",
      "71\n",
      "Bernoulli Naive Bayes\n",
      "72\n",
      "Bernoulli Naive Bayes\n",
      "73\n",
      "Bernoulli Naive Bayes\n",
      "74\n",
      "Bernoulli Naive Bayes\n",
      "75\n",
      "Bernoulli Naive Bayes\n",
      "76\n",
      "Bernoulli Naive Bayes\n",
      "77\n",
      "Bernoulli Naive Bayes\n",
      "78\n",
      "Bernoulli Naive Bayes\n",
      "79\n",
      "Bernoulli Naive Bayes\n",
      "80\n",
      "Bernoulli Naive Bayes\n",
      "81\n",
      "Bernoulli Naive Bayes\n",
      "82\n",
      "Bernoulli Naive Bayes\n",
      "83\n",
      "Bernoulli Naive Bayes\n",
      "84\n",
      "Bernoulli Naive Bayes\n",
      "85\n",
      "Bernoulli Naive Bayes\n",
      "86\n",
      "Bernoulli Naive Bayes\n",
      "87\n",
      "Bernoulli Naive Bayes\n",
      "88\n",
      "Bernoulli Naive Bayes\n",
      "89\n",
      "Bernoulli Naive Bayes\n",
      "90\n",
      "Bernoulli Naive Bayes\n",
      "91\n",
      "Bernoulli Naive Bayes\n",
      "92\n",
      "Bernoulli Naive Bayes\n",
      "93\n",
      "Bernoulli Naive Bayes\n",
      "94\n",
      "Bernoulli Naive Bayes\n",
      "95\n",
      "Bernoulli Naive Bayes\n",
      "96\n",
      "Bernoulli Naive Bayes\n",
      "97\n",
      "Bernoulli Naive Bayes\n",
      "98\n",
      "Bernoulli Naive Bayes\n",
      "99\n",
      "Bernoulli Naive Bayes\n",
      "100\n",
      "Bernoulli Naive Bayes\n",
      "101\n",
      "Bernoulli Naive Bayes\n",
      "102\n",
      "Bernoulli Naive Bayes\n",
      "103\n",
      "Bernoulli Naive Bayes\n",
      "104\n",
      "Bernoulli Naive Bayes\n",
      "105\n",
      "Bernoulli Naive Bayes\n",
      "106\n",
      "Bernoulli Naive Bayes\n",
      "107\n",
      "Bernoulli Naive Bayes\n",
      "108\n",
      "Bernoulli Naive Bayes\n",
      "109\n",
      "Bernoulli Naive Bayes\n",
      "110\n",
      "Bernoulli Naive Bayes\n",
      "111\n",
      "Bernoulli Naive Bayes\n",
      "112\n",
      "Bernoulli Naive Bayes\n",
      "113\n",
      "Bernoulli Naive Bayes\n",
      "114\n",
      "Bernoulli Naive Bayes\n",
      "115\n",
      "Bernoulli Naive Bayes\n",
      "116\n",
      "Bernoulli Naive Bayes\n",
      "117\n",
      "Bernoulli Naive Bayes\n",
      "118\n",
      "Bernoulli Naive Bayes\n",
      "119\n",
      "Bernoulli Naive Bayes\n",
      "120\n",
      "Bernoulli Naive Bayes\n",
      "121\n",
      "Random Forest Classifier\n",
      "122\n",
      "Random Forest Classifier\n",
      "123\n",
      "Random Forest Classifier\n",
      "124\n",
      "Random Forest Classifier\n",
      "125\n",
      "Random Forest Classifier\n",
      "126\n",
      "Random Forest Classifier\n",
      "127\n",
      "Random Forest Classifier\n",
      "128\n",
      "Random Forest Classifier\n",
      "129\n",
      "Random Forest Classifier\n",
      "130\n",
      "Random Forest Classifier\n",
      "131\n",
      "Random Forest Classifier\n",
      "132\n",
      "Random Forest Classifier\n",
      "133\n",
      "Random Forest Classifier\n",
      "134\n",
      "Random Forest Classifier\n",
      "135\n",
      "Random Forest Classifier\n",
      "136\n",
      "Random Forest Classifier\n",
      "137\n",
      "Random Forest Classifier\n",
      "138\n",
      "Random Forest Classifier\n",
      "139\n",
      "Random Forest Classifier\n",
      "140\n",
      "Random Forest Classifier\n",
      "141\n",
      "Random Forest Classifier\n",
      "142\n",
      "Random Forest Classifier\n",
      "143\n",
      "Random Forest Classifier\n",
      "144\n",
      "Random Forest Classifier\n",
      "145\n",
      "Random Forest Classifier\n",
      "146\n",
      "Random Forest Classifier\n",
      "147\n",
      "Random Forest Classifier\n",
      "148\n",
      "Random Forest Classifier\n",
      "149\n",
      "Random Forest Classifier\n",
      "150\n",
      "Random Forest Classifier\n",
      "151\n",
      "Random Forest Classifier\n",
      "152\n",
      "Random Forest Classifier\n",
      "153\n",
      "Random Forest Classifier\n",
      "154\n",
      "Random Forest Classifier\n",
      "155\n",
      "Random Forest Classifier\n",
      "156\n",
      "Random Forest Classifier\n",
      "157\n",
      "Random Forest Classifier\n",
      "158\n",
      "Random Forest Classifier\n",
      "159\n",
      "Random Forest Classifier\n",
      "160\n",
      "Random Forest Classifier\n",
      "161\n",
      "Random Forest Classifier\n",
      "162\n",
      "Random Forest Classifier\n",
      "163\n",
      "Random Forest Classifier\n",
      "164\n",
      "Random Forest Classifier\n",
      "165\n",
      "Random Forest Classifier\n",
      "166\n",
      "Random Forest Classifier\n",
      "167\n",
      "Random Forest Classifier\n",
      "168\n",
      "Random Forest Classifier\n",
      "169\n",
      "Random Forest Classifier\n",
      "170\n",
      "Random Forest Classifier\n",
      "171\n",
      "Random Forest Classifier\n",
      "172\n",
      "Random Forest Classifier\n",
      "173\n",
      "Random Forest Classifier\n",
      "174\n",
      "Random Forest Classifier\n",
      "175\n",
      "Random Forest Classifier\n",
      "176\n",
      "Random Forest Classifier\n",
      "177\n",
      "Random Forest Classifier\n",
      "178\n",
      "Random Forest Classifier\n",
      "179\n",
      "Random Forest Classifier\n",
      "180\n",
      "Random Forest Classifier\n",
      "181\n",
      "Random Forest Classifier\n",
      "182\n",
      "Random Forest Classifier\n",
      "183\n",
      "Random Forest Classifier\n",
      "184\n",
      "Random Forest Classifier\n",
      "185\n",
      "Random Forest Classifier\n",
      "186\n",
      "Random Forest Classifier\n",
      "187\n",
      "Random Forest Classifier\n",
      "188\n",
      "Random Forest Classifier\n",
      "189\n",
      "Random Forest Classifier\n",
      "190\n",
      "Random Forest Classifier\n",
      "191\n",
      "Random Forest Classifier\n",
      "192\n",
      "Random Forest Classifier\n",
      "193\n",
      "Random Forest Classifier\n",
      "194\n",
      "Random Forest Classifier\n",
      "195\n",
      "Random Forest Classifier\n",
      "196\n",
      "Random Forest Classifier\n",
      "197\n",
      "Random Forest Classifier\n",
      "198\n",
      "Random Forest Classifier\n",
      "199\n",
      "Random Forest Classifier\n",
      "200\n",
      "Random Forest Classifier\n",
      "201\n",
      "Random Forest Classifier\n",
      "202\n",
      "Random Forest Classifier\n",
      "203\n",
      "Random Forest Classifier\n",
      "204\n",
      "Random Forest Classifier\n",
      "205\n",
      "Random Forest Classifier\n",
      "206\n",
      "Random Forest Classifier\n",
      "207\n",
      "Random Forest Classifier\n",
      "208\n",
      "Random Forest Classifier\n",
      "209\n",
      "Random Forest Classifier\n",
      "210\n",
      "Random Forest Classifier\n",
      "211\n",
      "Random Forest Classifier\n",
      "212\n",
      "Random Forest Classifier\n",
      "213\n",
      "Random Forest Classifier\n",
      "214\n",
      "Random Forest Classifier\n",
      "215\n",
      "Random Forest Classifier\n",
      "216\n",
      "Random Forest Classifier\n",
      "217\n",
      "Random Forest Classifier\n",
      "218\n",
      "Random Forest Classifier\n",
      "219\n",
      "Random Forest Classifier\n",
      "220\n",
      "Random Forest Classifier\n",
      "221\n",
      "Random Forest Classifier\n",
      "222\n",
      "Random Forest Classifier\n",
      "223\n",
      "Random Forest Classifier\n",
      "224\n",
      "Random Forest Classifier\n",
      "225\n",
      "Random Forest Classifier\n",
      "226\n",
      "Random Forest Classifier\n",
      "227\n",
      "Random Forest Classifier\n",
      "228\n",
      "Random Forest Classifier\n",
      "229\n",
      "Random Forest Classifier\n",
      "230\n",
      "Random Forest Classifier\n",
      "231\n",
      "Random Forest Classifier\n",
      "232\n",
      "Random Forest Classifier\n",
      "233\n",
      "Random Forest Classifier\n",
      "234\n",
      "Random Forest Classifier\n",
      "235\n",
      "Random Forest Classifier\n",
      "236\n",
      "Random Forest Classifier\n",
      "237\n",
      "Random Forest Classifier\n",
      "238\n",
      "Random Forest Classifier\n",
      "239\n",
      "Random Forest Classifier\n",
      "240\n",
      "Random Forest Classifier\n",
      "241\n",
      "Logistic Regression (Ridge)\n",
      "242\n",
      "Logistic Regression (Ridge)\n",
      "243\n",
      "Logistic Regression (Ridge)\n",
      "244\n",
      "Logistic Regression (Ridge)\n",
      "245\n",
      "Logistic Regression (Ridge)\n",
      "246\n",
      "Logistic Regression (Ridge)\n",
      "247\n",
      "Logistic Regression (Ridge)\n",
      "248\n",
      "Logistic Regression (Ridge)\n",
      "249\n",
      "Logistic Regression (Ridge)\n",
      "250\n",
      "Logistic Regression (Ridge)\n",
      "251\n",
      "Logistic Regression (Ridge)\n",
      "252\n",
      "Logistic Regression (Ridge)\n",
      "253\n",
      "Logistic Regression (Ridge)\n",
      "254\n",
      "Logistic Regression (Ridge)\n",
      "255\n",
      "Logistic Regression (Ridge)\n",
      "256\n",
      "Logistic Regression (Ridge)\n",
      "257\n",
      "Logistic Regression (Ridge)\n",
      "258\n",
      "Logistic Regression (Ridge)\n",
      "259\n",
      "Logistic Regression (Ridge)\n",
      "260\n",
      "Logistic Regression (Ridge)\n",
      "261\n",
      "Logistic Regression (Ridge)\n",
      "262\n",
      "Logistic Regression (Ridge)\n",
      "263\n",
      "Logistic Regression (Ridge)\n",
      "264\n",
      "Logistic Regression (Ridge)\n",
      "265\n",
      "Logistic Regression (Ridge)\n",
      "266\n",
      "Logistic Regression (Ridge)\n",
      "267\n",
      "Logistic Regression (Ridge)\n",
      "268\n",
      "Logistic Regression (Ridge)\n",
      "269\n",
      "Logistic Regression (Ridge)\n",
      "270\n",
      "Logistic Regression (Ridge)\n",
      "271\n",
      "Logistic Regression (Ridge)\n",
      "272\n",
      "Logistic Regression (Ridge)\n",
      "273\n",
      "Logistic Regression (Ridge)\n",
      "274\n",
      "Logistic Regression (Ridge)\n",
      "275\n",
      "Logistic Regression (Ridge)\n",
      "276\n",
      "Logistic Regression (Ridge)\n",
      "277\n",
      "Logistic Regression (Ridge)\n",
      "278\n",
      "Logistic Regression (Ridge)\n",
      "279\n",
      "Logistic Regression (Ridge)\n",
      "280\n",
      "Logistic Regression (Ridge)\n",
      "281\n",
      "Logistic Regression (Ridge)\n",
      "282\n",
      "Logistic Regression (Ridge)\n",
      "283\n",
      "Logistic Regression (Ridge)\n",
      "284\n",
      "Logistic Regression (Ridge)\n",
      "285\n",
      "Logistic Regression (Ridge)\n",
      "286\n",
      "Logistic Regression (Ridge)\n",
      "287\n",
      "Logistic Regression (Ridge)\n",
      "288\n",
      "Logistic Regression (Ridge)\n",
      "289\n",
      "Logistic Regression (Ridge)\n",
      "290\n",
      "Logistic Regression (Ridge)\n",
      "291\n",
      "Logistic Regression (Ridge)\n",
      "292\n",
      "Logistic Regression (Ridge)\n",
      "293\n",
      "Logistic Regression (Ridge)\n",
      "294\n",
      "Logistic Regression (Ridge)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n",
      "Logistic Regression (Ridge)\n",
      "296\n",
      "Logistic Regression (Ridge)\n",
      "297\n",
      "Logistic Regression (Ridge)\n",
      "298\n",
      "Logistic Regression (Ridge)\n",
      "299\n",
      "Logistic Regression (Ridge)\n",
      "300\n",
      "Logistic Regression (Ridge)\n",
      "301\n",
      "Logistic Regression (Ridge)\n",
      "302\n",
      "Logistic Regression (Ridge)\n",
      "303\n",
      "Logistic Regression (Ridge)\n",
      "304\n",
      "Logistic Regression (Ridge)\n",
      "305\n",
      "Logistic Regression (Ridge)\n",
      "306\n",
      "Logistic Regression (Ridge)\n",
      "307\n",
      "Logistic Regression (Ridge)\n",
      "308\n",
      "Logistic Regression (Ridge)\n",
      "309\n",
      "Logistic Regression (Ridge)\n",
      "310\n",
      "Logistic Regression (Ridge)\n",
      "311\n",
      "Logistic Regression (Ridge)\n",
      "312\n",
      "Logistic Regression (Ridge)\n",
      "313\n",
      "Logistic Regression (Ridge)\n",
      "314\n",
      "Logistic Regression (Ridge)\n",
      "315\n",
      "Logistic Regression (Ridge)\n",
      "316\n",
      "Logistic Regression (Ridge)\n",
      "317\n",
      "Logistic Regression (Ridge)\n",
      "318\n",
      "Logistic Regression (Ridge)\n",
      "319\n",
      "Logistic Regression (Ridge)\n",
      "320\n",
      "Logistic Regression (Ridge)\n",
      "321\n",
      "Logistic Regression (Ridge)\n",
      "322\n",
      "Logistic Regression (Ridge)\n",
      "323\n",
      "Logistic Regression (Ridge)\n",
      "324\n",
      "Logistic Regression (Ridge)\n",
      "325\n",
      "Logistic Regression (Ridge)\n",
      "326\n",
      "Logistic Regression (Ridge)\n",
      "327\n",
      "Logistic Regression (Ridge)\n",
      "328\n",
      "Logistic Regression (Ridge)\n",
      "329\n",
      "Logistic Regression (Ridge)\n",
      "330\n",
      "Logistic Regression (Ridge)\n",
      "331\n",
      "Logistic Regression (Ridge)\n",
      "332\n",
      "Logistic Regression (Ridge)\n",
      "333\n",
      "Logistic Regression (Ridge)\n",
      "334\n",
      "Logistic Regression (Ridge)\n",
      "335\n",
      "Logistic Regression (Ridge)\n",
      "336\n",
      "Logistic Regression (Ridge)\n",
      "337\n",
      "Logistic Regression (Ridge)\n",
      "338\n",
      "Logistic Regression (Ridge)\n",
      "339\n",
      "Logistic Regression (Ridge)\n",
      "340\n",
      "Logistic Regression (Ridge)\n",
      "341\n",
      "Logistic Regression (Ridge)\n",
      "342\n",
      "Logistic Regression (Ridge)\n",
      "343\n",
      "Logistic Regression (Ridge)\n",
      "344\n",
      "Logistic Regression (Ridge)\n",
      "345\n",
      "Logistic Regression (Ridge)\n",
      "346\n",
      "Logistic Regression (Ridge)\n",
      "347\n",
      "Logistic Regression (Ridge)\n",
      "348\n",
      "Logistic Regression (Ridge)\n",
      "349\n",
      "Logistic Regression (Ridge)\n",
      "350\n",
      "Logistic Regression (Ridge)\n",
      "351\n",
      "Logistic Regression (Ridge)\n",
      "352\n",
      "Logistic Regression (Ridge)\n",
      "353\n",
      "Logistic Regression (Ridge)\n",
      "354\n",
      "Logistic Regression (Ridge)\n",
      "355\n",
      "Logistic Regression (Ridge)\n",
      "356\n",
      "Logistic Regression (Ridge)\n",
      "357\n",
      "Logistic Regression (Ridge)\n",
      "358\n",
      "Logistic Regression (Ridge)\n",
      "359\n",
      "Logistic Regression (Ridge)\n",
      "360\n",
      "Logistic Regression (Ridge)\n",
      "361\n",
      "Logistic Regression (Lasso)\n",
      "362\n",
      "Logistic Regression (Lasso)\n",
      "363\n",
      "Logistic Regression (Lasso)\n",
      "364\n",
      "Logistic Regression (Lasso)\n",
      "365\n",
      "Logistic Regression (Lasso)\n",
      "366\n",
      "Logistic Regression (Lasso)\n",
      "367\n",
      "Logistic Regression (Lasso)\n",
      "368\n",
      "Logistic Regression (Lasso)\n",
      "369\n",
      "Logistic Regression (Lasso)\n",
      "370\n",
      "Logistic Regression (Lasso)\n",
      "371\n",
      "Logistic Regression (Lasso)\n",
      "372\n",
      "Logistic Regression (Lasso)\n",
      "373\n",
      "Logistic Regression (Lasso)\n",
      "374\n",
      "Logistic Regression (Lasso)\n",
      "375\n",
      "Logistic Regression (Lasso)\n",
      "376\n",
      "Logistic Regression (Lasso)\n",
      "377\n",
      "Logistic Regression (Lasso)\n",
      "378\n",
      "Logistic Regression (Lasso)\n",
      "379\n",
      "Logistic Regression (Lasso)\n",
      "380\n",
      "Logistic Regression (Lasso)\n",
      "381\n",
      "Logistic Regression (Lasso)\n",
      "382\n",
      "Logistic Regression (Lasso)\n",
      "383\n",
      "Logistic Regression (Lasso)\n",
      "384\n",
      "Logistic Regression (Lasso)\n",
      "385\n",
      "Logistic Regression (Lasso)\n",
      "386\n",
      "Logistic Regression (Lasso)\n",
      "387\n",
      "Logistic Regression (Lasso)\n",
      "388\n",
      "Logistic Regression (Lasso)\n",
      "389\n",
      "Logistic Regression (Lasso)\n",
      "390\n",
      "Logistic Regression (Lasso)\n",
      "391\n",
      "Logistic Regression (Lasso)\n",
      "392\n",
      "Logistic Regression (Lasso)\n",
      "393\n",
      "Logistic Regression (Lasso)\n",
      "394\n",
      "Logistic Regression (Lasso)\n",
      "395\n",
      "Logistic Regression (Lasso)\n",
      "396\n",
      "Logistic Regression (Lasso)\n",
      "397\n",
      "Logistic Regression (Lasso)\n",
      "398\n",
      "Logistic Regression (Lasso)\n",
      "399\n",
      "Logistic Regression (Lasso)\n",
      "400\n",
      "Logistic Regression (Lasso)\n",
      "401\n",
      "Logistic Regression (Lasso)\n",
      "402\n",
      "Logistic Regression (Lasso)\n",
      "403\n",
      "Logistic Regression (Lasso)\n",
      "404\n",
      "Logistic Regression (Lasso)\n",
      "405\n",
      "Logistic Regression (Lasso)\n",
      "406\n",
      "Logistic Regression (Lasso)\n",
      "407\n",
      "Logistic Regression (Lasso)\n",
      "408\n",
      "Logistic Regression (Lasso)\n",
      "409\n",
      "Logistic Regression (Lasso)\n",
      "410\n",
      "Logistic Regression (Lasso)\n",
      "411\n",
      "Logistic Regression (Lasso)\n",
      "412\n",
      "Logistic Regression (Lasso)\n",
      "413\n",
      "Logistic Regression (Lasso)\n",
      "414\n",
      "Logistic Regression (Lasso)\n",
      "415\n",
      "Logistic Regression (Lasso)\n",
      "416\n",
      "Logistic Regression (Lasso)\n",
      "417\n",
      "Logistic Regression (Lasso)\n",
      "418\n",
      "Logistic Regression (Lasso)\n",
      "419\n",
      "Logistic Regression (Lasso)\n",
      "420\n",
      "Logistic Regression (Lasso)\n",
      "421\n",
      "Logistic Regression (Lasso)\n",
      "422\n",
      "Logistic Regression (Lasso)\n",
      "423\n",
      "Logistic Regression (Lasso)\n",
      "424\n",
      "Logistic Regression (Lasso)\n",
      "425\n",
      "Logistic Regression (Lasso)\n",
      "426\n",
      "Logistic Regression (Lasso)\n",
      "427\n",
      "Logistic Regression (Lasso)\n",
      "428\n",
      "Logistic Regression (Lasso)\n",
      "429\n",
      "Logistic Regression (Lasso)\n",
      "430\n",
      "Logistic Regression (Lasso)\n",
      "431\n",
      "Logistic Regression (Lasso)\n",
      "432\n",
      "Logistic Regression (Lasso)\n",
      "433\n",
      "Logistic Regression (Lasso)\n",
      "434\n",
      "Logistic Regression (Lasso)\n",
      "435\n",
      "Logistic Regression (Lasso)\n",
      "436\n",
      "Logistic Regression (Lasso)\n",
      "437\n",
      "Logistic Regression (Lasso)\n",
      "438\n",
      "Logistic Regression (Lasso)\n",
      "439\n",
      "Logistic Regression (Lasso)\n",
      "440\n",
      "Logistic Regression (Lasso)\n",
      "441\n",
      "Logistic Regression (Lasso)\n",
      "442\n",
      "Logistic Regression (Lasso)\n",
      "443\n",
      "Logistic Regression (Lasso)\n",
      "444\n",
      "Logistic Regression (Lasso)\n",
      "445\n",
      "Logistic Regression (Lasso)\n",
      "446\n",
      "Logistic Regression (Lasso)\n",
      "447\n",
      "Logistic Regression (Lasso)\n",
      "448\n",
      "Logistic Regression (Lasso)\n",
      "449\n",
      "Logistic Regression (Lasso)\n",
      "450\n",
      "Logistic Regression (Lasso)\n",
      "451\n",
      "Logistic Regression (Lasso)\n",
      "452\n",
      "Logistic Regression (Lasso)\n",
      "453\n",
      "Logistic Regression (Lasso)\n",
      "454\n",
      "Logistic Regression (Lasso)\n",
      "455\n",
      "Logistic Regression (Lasso)\n",
      "456\n",
      "Logistic Regression (Lasso)\n",
      "457\n",
      "Logistic Regression (Lasso)\n",
      "458\n",
      "Logistic Regression (Lasso)\n",
      "459\n",
      "Logistic Regression (Lasso)\n",
      "460\n",
      "Logistic Regression (Lasso)\n",
      "461\n",
      "Logistic Regression (Lasso)\n",
      "462\n",
      "Logistic Regression (Lasso)\n",
      "463\n",
      "Logistic Regression (Lasso)\n",
      "464\n",
      "Logistic Regression (Lasso)\n",
      "465\n",
      "Logistic Regression (Lasso)\n",
      "466\n",
      "Logistic Regression (Lasso)\n",
      "467\n",
      "Logistic Regression (Lasso)\n",
      "468\n",
      "Logistic Regression (Lasso)\n",
      "469\n",
      "Logistic Regression (Lasso)\n",
      "470\n",
      "Logistic Regression (Lasso)\n",
      "471\n",
      "Logistic Regression (Lasso)\n",
      "472\n",
      "Logistic Regression (Lasso)\n",
      "473\n",
      "Logistic Regression (Lasso)\n",
      "474\n",
      "Logistic Regression (Lasso)\n",
      "475\n",
      "Logistic Regression (Lasso)\n",
      "476\n",
      "Logistic Regression (Lasso)\n",
      "477\n",
      "Logistic Regression (Lasso)\n",
      "478\n",
      "Logistic Regression (Lasso)\n",
      "479\n",
      "Logistic Regression (Lasso)\n",
      "480\n",
      "Logistic Regression (Lasso)\n"
     ]
    }
   ],
   "source": [
    "model_result_df = pd.DataFrame()\n",
    "index = 1\n",
    "for mn in range(len(model_name)):\n",
    "    for tm in training_method:\n",
    "        for b in balanced:\n",
    "            for ss in sampling_size:\n",
    "                for t in sort_by_time:\n",
    "                    for r in partition_ratio:\n",
    "                        print(index)\n",
    "                        print(model_name[mn])\n",
    "                        model_output = trial(df, model_name[mn], mn, tm, b, ss, t, r)\n",
    "                        if index == 0:\n",
    "                            model_result_df = pd.DataFrame(model_output, index=index)\n",
    "                        else:\n",
    "                            model_result_df = model_result_df.append(pd.DataFrame([model_output],index=[index]))\n",
    "                        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bce332de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>training_method</th>\n",
       "      <th>balance</th>\n",
       "      <th>sampling_size</th>\n",
       "      <th>sort_by_time</th>\n",
       "      <th>partition_ratio</th>\n",
       "      <th>seed_size</th>\n",
       "      <th>unlabeled_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>val_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>5073</td>\n",
       "      <td>2536</td>\n",
       "      <td>2538</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.6, 0.2, 0.2]</td>\n",
       "      <td>6088</td>\n",
       "      <td>2029</td>\n",
       "      <td>2030</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.8, 0.1, 0.1]</td>\n",
       "      <td>8117</td>\n",
       "      <td>1014</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>5073</td>\n",
       "      <td>2536</td>\n",
       "      <td>2538</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.6, 0.2, 0.2]</td>\n",
       "      <td>6088</td>\n",
       "      <td>2029</td>\n",
       "      <td>2030</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_name  training_method  balance  sampling_size  \\\n",
       "1  Bernoulli Naive Bayes  random_sampling     True              0   \n",
       "2  Bernoulli Naive Bayes  random_sampling     True              0   \n",
       "3  Bernoulli Naive Bayes  random_sampling     True              0   \n",
       "4  Bernoulli Naive Bayes  random_sampling     True              0   \n",
       "5  Bernoulli Naive Bayes  random_sampling     True              0   \n",
       "\n",
       "   sort_by_time    partition_ratio  seed_size  unlabeled_size  test_size  \\\n",
       "1          True  [0.5, 0.25, 0.25]       5073            2536       2538   \n",
       "2          True    [0.6, 0.2, 0.2]       6088            2029       2030   \n",
       "3          True    [0.8, 0.1, 0.1]       8117            1014       1016   \n",
       "4         False  [0.5, 0.25, 0.25]       5073            2536       2538   \n",
       "5         False    [0.6, 0.2, 0.2]       6088            2029       2030   \n",
       "\n",
       "   val_score  accuracy  f1_score  precision  recall  specificity  \n",
       "1      0.796     0.835     0.905      0.836   0.987        0.240  \n",
       "2      0.810     0.830     0.902      0.835   0.980        0.240  \n",
       "3      0.807     0.833     0.903      0.839   0.978        0.266  \n",
       "4      0.796     0.837     0.904      0.851   0.964        0.337  \n",
       "5      0.814     0.840     0.905      0.859   0.956        0.387  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c583f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result_df.to_csv('bucket_model_result.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3340e961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 15)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75d77f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>training_method</th>\n",
       "      <th>balance</th>\n",
       "      <th>sampling_size</th>\n",
       "      <th>sort_by_time</th>\n",
       "      <th>partition_ratio</th>\n",
       "      <th>seed_size</th>\n",
       "      <th>unlabeled_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>val_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>5073</td>\n",
       "      <td>2536</td>\n",
       "      <td>2538</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.6, 0.2, 0.2]</td>\n",
       "      <td>6088</td>\n",
       "      <td>2029</td>\n",
       "      <td>2030</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.8, 0.1, 0.1]</td>\n",
       "      <td>8117</td>\n",
       "      <td>1014</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>5073</td>\n",
       "      <td>2536</td>\n",
       "      <td>2538</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bernoulli Naive Bayes</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.6, 0.2, 0.2]</td>\n",
       "      <td>6088</td>\n",
       "      <td>2029</td>\n",
       "      <td>2030</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Logistic Regression (Lasso)</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.6, 0.2, 0.2]</td>\n",
       "      <td>6088</td>\n",
       "      <td>2029</td>\n",
       "      <td>2030</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>Logistic Regression (Lasso)</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.8, 0.1, 0.1]</td>\n",
       "      <td>8117</td>\n",
       "      <td>1014</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Logistic Regression (Lasso)</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.5, 0.25, 0.25]</td>\n",
       "      <td>5073</td>\n",
       "      <td>2536</td>\n",
       "      <td>2538</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>Logistic Regression (Lasso)</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.6, 0.2, 0.2]</td>\n",
       "      <td>6088</td>\n",
       "      <td>2029</td>\n",
       "      <td>2030</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Logistic Regression (Lasso)</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.8, 0.1, 0.1]</td>\n",
       "      <td>8117</td>\n",
       "      <td>1014</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model_name  training_method  balance  sampling_size  \\\n",
       "1          Bernoulli Naive Bayes  random_sampling     True              0   \n",
       "2          Bernoulli Naive Bayes  random_sampling     True              0   \n",
       "3          Bernoulli Naive Bayes  random_sampling     True              0   \n",
       "4          Bernoulli Naive Bayes  random_sampling     True              0   \n",
       "5          Bernoulli Naive Bayes  random_sampling     True              0   \n",
       "..                           ...              ...      ...            ...   \n",
       "476  Logistic Regression (Lasso)  active_learning    False            600   \n",
       "477  Logistic Regression (Lasso)  active_learning    False            600   \n",
       "478  Logistic Regression (Lasso)  active_learning    False            600   \n",
       "479  Logistic Regression (Lasso)  active_learning    False            600   \n",
       "480  Logistic Regression (Lasso)  active_learning    False            600   \n",
       "\n",
       "     sort_by_time    partition_ratio  seed_size  unlabeled_size  test_size  \\\n",
       "1            True  [0.5, 0.25, 0.25]       5073            2536       2538   \n",
       "2            True    [0.6, 0.2, 0.2]       6088            2029       2030   \n",
       "3            True    [0.8, 0.1, 0.1]       8117            1014       1016   \n",
       "4           False  [0.5, 0.25, 0.25]       5073            2536       2538   \n",
       "5           False    [0.6, 0.2, 0.2]       6088            2029       2030   \n",
       "..            ...                ...        ...             ...        ...   \n",
       "476          True    [0.6, 0.2, 0.2]       6088            2029       2030   \n",
       "477          True    [0.8, 0.1, 0.1]       8117            1014       1016   \n",
       "478         False  [0.5, 0.25, 0.25]       5073            2536       2538   \n",
       "479         False    [0.6, 0.2, 0.2]       6088            2029       2030   \n",
       "480         False    [0.8, 0.1, 0.1]       8117            1014       1016   \n",
       "\n",
       "     val_score  accuracy  f1_score  precision  recall  specificity  \n",
       "1        0.796     0.835     0.905      0.836   0.987        0.240  \n",
       "2        0.810     0.830     0.902      0.835   0.980        0.240  \n",
       "3        0.807     0.833     0.903      0.839   0.978        0.266  \n",
       "4        0.796     0.837     0.904      0.851   0.964        0.337  \n",
       "5        0.814     0.840     0.905      0.859   0.956        0.387  \n",
       "..         ...       ...       ...        ...     ...          ...  \n",
       "476      0.784     0.837     0.904      0.848   0.969        0.320  \n",
       "477      0.820     0.844     0.909      0.850   0.978        0.324  \n",
       "478      0.786     0.831     0.896      0.876   0.918        0.490  \n",
       "479      0.814     0.839     0.902      0.881   0.923        0.511  \n",
       "480      0.817     0.851     0.909      0.888   0.931        0.541  \n",
       "\n",
       "[480 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d908a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
