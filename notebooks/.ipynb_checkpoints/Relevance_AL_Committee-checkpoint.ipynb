{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e04c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import unidecode\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4226012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022 = pd.read_csv('../data/tweet_data_2022.csv')\n",
    "df_2023 = pd.read_csv('../data/tweet_data_2023.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6665c20",
   "metadata": {},
   "source": [
    "### Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b6b2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_number = 3\n",
    "random_state = 42\n",
    "categories = ['Bucket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09f8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_bucket(bucket):\n",
    "    if ((bucket == '1.0') | (bucket == '1')):\n",
    "        return '1'\n",
    "    elif ((bucket == '2') | (bucket == '3') | (bucket == '2.0') | (bucket == '3.0')):\n",
    "        return '2 or 3'\n",
    "    else:\n",
    "        return bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3034b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if type(text) == np.float:\n",
    "        return \"\"\n",
    "    temp = text.lower() # to lower case\n",
    "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp) # remove @s\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp) # remove hashtags\n",
    "    temp = re.sub(r'http\\S+', '', temp) # remove links\n",
    "    temp = re.sub(r\"www.\\S+\", \"\", temp) # remove links\n",
    "    temp = re.sub(r'\\n|[^a-zA-Z]', ' ', temp) # remove punctuation\n",
    "    temp = temp.replace(\"\\n\", \" \").split()\n",
    "    temp = [w for w in temp if not w in stopwords_] # remove stopwords\n",
    "    temp = [w for w in temp if not w.isdigit()] # remove numbers\n",
    "    temp = [unidecode.unidecode(w) for w in temp] # turn non-enlish letters to english letters\n",
    "    temp = \" \".join(word for word in temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04826dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(df, ratio, time):\n",
    "    #partiton\n",
    "    if time:\n",
    "        df.sort_values(by=['date'], inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "    df_rows = df.shape[0]\n",
    "    seed_num = math.floor(df_rows * ratio[0])\n",
    "    seed = df[:seed_num]\n",
    "    unlabeled_num = seed_num + (math.floor(df_rows * ratio[1]))\n",
    "    unlabeled = df[seed_num:unlabeled_num]\n",
    "    test = df[unlabeled_num:]\n",
    "    return seed, unlabeled, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d091725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(seed):\n",
    "    cv = 5\n",
    "    train, test = train_test_split(seed, random_state=random_state, test_size=0.2, shuffle=True)\n",
    "    X_train, X_test, Y_train, Y_test = train[['text_cleaned']], test[['text_cleaned']], train[['Bucket']], test[['Bucket']]\n",
    "    #Wrap in ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tf\", CountVectorizer(stop_words=stopwords_), 'text_cleaned'),\n",
    "            (\"tfidf\", TfidfVectorizer(stop_words=stopwords_), 'text_cleaned')]\n",
    "    )\n",
    "    #Define the model\n",
    "    model_lst = [\n",
    "                SVC(),\n",
    "                KNeighborsClassifier(),\n",
    "                DecisionTreeClassifier(),\n",
    "                RandomForestClassifier(),\n",
    "                AdaBoostClassifier(),\n",
    "#                  SVC(kernel='rbf', probability=True, random_state=random_state), #SVC RBF\n",
    "#                  SVC(kernel='poly', probability=True, degree=4, random_state=random_state), #SVC Poly\n",
    "#                  BernoulliNB(fit_prior=True, class_prior=None), #Naive Bayes\n",
    "#                  RandomForestClassifier(random_state=random_state), #Random Forest\n",
    "#                  LogisticRegression(solver='sag', random_state=random_state), #Logistic Regression (Ridge)\n",
    "#                  LogisticRegression(C=1, penalty='l1', solver='liblinear', random_state=random_state), #Logistic Regression (Lasso)\n",
    "            ]\n",
    "#     model = model_lst[model_index]\n",
    "    \n",
    "    pl_preds = []\n",
    "    for model in model_lst:\n",
    "        #Build the pipeline\n",
    "        pipeline = Pipeline([\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('clf', OneVsRestClassifier(model, n_jobs=1)),\n",
    "                ])\n",
    "        #Train the model\n",
    "        pipeline.fit(X_train, Y_train)\n",
    "        # compute the testing accuracy\n",
    "        prediction = pipeline.predict(pd.DataFrame(X_test))\n",
    "        pl_preds.append([pipeline, prediction])\n",
    "        \n",
    "    #Saves all the model pipelines\n",
    "    pipelines = [x[0] for x in pl_preds]\n",
    "    #Saves all the model predictions\n",
    "    all_preds = np.array([x[1] for x in pl_preds]).transpose()\n",
    "    #Find the mode in all preds\n",
    "    final_preds = [mode(i) for i in all_preds]\n",
    "    accuracy = accuracy_score(Y_test,final_preds)\n",
    "    return pipelines, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "836d90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(lst):\n",
    "    unique_num = list(set(lst))\n",
    "    entropy = 0\n",
    "    for i in range(len(unique_num)):\n",
    "        label = unique_num[i]\n",
    "        prob = sum(np.array(lst) == label)/len(lst)\n",
    "        entropy += prob * math.log2(1/prob)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39aef465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_unlabeled(pipelines, unlabeled):\n",
    "    unlabeled_x = unlabeled[['text_cleaned']]\n",
    "    unlabeled_y = unlabeled[['Bucket']]\n",
    "    all_preds = np.array([pl.predict(unlabeled_x) for pl in pipelines]).transpose()\n",
    "    unlabeled['all_preds'] = list(all_preds)\n",
    "    unlabeled['entropy'] = unlabeled['all_preds'].apply(calc_entropy)\n",
    "    unlabeled.sort_values(by=['entropy'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4a29a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learning(pipelines, seed, unlabeled, instances):\n",
    "    # Sort the unlabeled data based on informativeness level\n",
    "    choose_unlabeled(pipelines, unlabeled)\n",
    "    # Update the unlabeled data and the info_data\n",
    "    info_data, unlabeled = unlabeled.iloc[:instances], unlabeled.iloc[instances:]\n",
    "    # Add selected data to the training set\n",
    "    seed = pd.concat([seed, info_data[['date', 'text', 'Bucket', 'text_cleaned']]])\n",
    "    pipelines, accuracy = train_model(seed)\n",
    "    return pipelines, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03fc5bf",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca671fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_stopwords = stopwords.words('english')\n",
    "additional_stopwords = ['none']\n",
    "original_stopwords.extend(additional_stopwords)\n",
    "stopwords_ = set(original_stopwords)\n",
    "\n",
    "#Selects only the tweets about China\n",
    "df = df_2022[df_2022['country']=='China']\n",
    "df = df[['date', 'text', 'id', 'Bucket', 'SentimentScore']]\n",
    "\n",
    "#Shuffle the data\n",
    "df = df.sample(frac=1, replace=False, random_state=1) \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#Standardized the bucket label\n",
    "df['Bucket'] = df['Bucket'].apply(standardize_bucket)\n",
    "#Remove tweets that are in both buckets\n",
    "df_bucket_count = pd.DataFrame(df.groupby('id')['Bucket'].nunique())\n",
    "df_bucket_count.reset_index(inplace=True)\n",
    "df_bucket_count.columns = ['tweet_id', 'bucket_num']\n",
    "df = df.merge(df_bucket_count, left_on='id', right_on='tweet_id')\n",
    "df = df[df['bucket_num'] == 1]\n",
    "#Remove tweets without a bucket (null)\n",
    "df = df[(df['Bucket'] == '1') | (df['Bucket'] == '2 or 3')]\n",
    "#Remove duplicates\n",
    "df = df.drop_duplicates(subset=['id']).reset_index(drop=True)\n",
    "df = df[['date', 'text', 'Bucket']]\n",
    "df[\"text_cleaned\"] = [clean_text(t) for t in df[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e7f3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(df, model_names, training_method, balance, sampling_size, sort_by_time, partition_ratio):\n",
    "    output = {}\n",
    "    output['model_names'] = model_names\n",
    "    output['training_method'] = training_method #random_sampling, active_learning\n",
    "    output['balance'] = balance\n",
    "    output['sampling_size'] = sampling_size\n",
    "    output['sort_by_time'] = sort_by_time\n",
    "    output['partition_ratio'] = partition_ratio\n",
    "        \n",
    "    # 1. Balance dataset \n",
    "    df_1, df_2_3 = df[df.Bucket=='1'], df[df.Bucket=='2 or 3']\n",
    "    df_lst = [df_1, df_2_3]\n",
    "    \n",
    "    # 1.1 Balance the label distribution  (50% Bucket 1 vs. 50% Non-Bucket 1)\n",
    "    if balance:\n",
    "        sample_size = min(df_1.shape[0], df_2_3.shape[0])\n",
    "        if df_1.shape[0] > sample_size:\n",
    "            df_1 = resample(df_1, replace=False, n_samples=sample_size, random_state=random_state)\n",
    "        if df_2_3.shape[0] > sample_size:\n",
    "            df_2_3 = resample(df_2_3, replace=False, n_samples=sample_size, random_state=random_state)\n",
    "            \n",
    "    # 1.2 Keep the natural label distribution\n",
    "    seed_1, unlabeled_1, test_1 = partition_data(df_1, partition_ratio, sort_by_time)\n",
    "    seed_2_3, unlabeled_2_3, test_2_3 = partition_data(df_2_3, partition_ratio, sort_by_time)\n",
    "    seed, unlabeled, test = pd.concat([seed_1, seed_2_3]), pd.concat([unlabeled_1, unlabeled_2_3]), pd.concat([test_1, test_2_3])\n",
    "    output['seed_size'], output['unlabeled_size'], output['test_size'] = seed.shape[0], unlabeled.shape[0], test.shape[0]\n",
    "    \n",
    "    initial_seed = seed.copy()\n",
    "    initial_unlabeled = unlabeled.copy()\n",
    "    \n",
    "    # 2. Train the model\n",
    "    initial_pipelines, initial_accuracy = train_model(initial_seed)\n",
    "    \n",
    "    # 3. Active Learning\n",
    "    if sampling_size == 0:\n",
    "        pipelines, accuracy = initial_pipelines, initial_accuracy\n",
    "        \n",
    "    # 3.1 Initial Model + Random Sampling\n",
    "    elif training_method == 'random_sampling':\n",
    "        if initial_unlabeled.shape[0] >= sampling_size:\n",
    "            sample_unlabeled = initial_unlabeled.sample(n=sampling_size, replace=False, random_state=random_state)\n",
    "        else:\n",
    "            sample_unlabeled = initial_unlabeled.sample(n=sampling_size, replace=True, random_state=random_state)\n",
    "        seed_and_sample_unlabeled_df = pd.concat([initial_seed, sample_unlabeled])\n",
    "        pipelines, accuracy = train_model(seed_and_sample_unlabeled_df)\n",
    "        \n",
    "    # 3.2 Initial Model + Active Learning\n",
    "    else:\n",
    "        pipelines, accuracy = active_learning(initial_pipelines, initial_seed, initial_unlabeled, sampling_size)\n",
    "\n",
    "    # 4. Report Model Accuracy\n",
    "    X_test, Y_test = test[['text_cleaned']], test[['Bucket']]\n",
    "    \n",
    "\n",
    "    pl_preds = []\n",
    "    for pl in pipelines:\n",
    "        # compute the testing accuracy\n",
    "        prediction = pl.predict(pd.DataFrame(X_test))\n",
    "        pl_preds.append([pl, prediction])\n",
    "        \n",
    "    #Saves all the model predictions\n",
    "    all_preds = np.array([x[1] for x in pl_preds]).transpose()\n",
    "    #Find the mode in all preds\n",
    "    prediction = [mode(i) for i in all_preds]\n",
    "    accuracy = round(accuracy_score(Y_test, prediction), round_number)\n",
    "    f1 = round(f1_score(np.array(Y_test), prediction, pos_label='1'), round_number)\n",
    "    precision = round(precision_score(np.array(Y_test), prediction, pos_label='1', average='binary'), round_number)\n",
    "    recall = round(recall_score(np.array(Y_test), prediction, pos_label='1', average='binary'), round_number)\n",
    "    specificity = round(recall_score(np.array(Y_test), prediction, pos_label='2 or 3', average='binary'), round_number)\n",
    "    output['accuracy'] = accuracy\n",
    "    output['f1_score'] = f1\n",
    "    output['precision'] = precision\n",
    "    output['recall'] = recall\n",
    "    output['specificity'] = specificity\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4063903",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_method = ['random_sampling', 'active_learning']\n",
    "balanced = [True, False]\n",
    "sampling_size = [0, 50, 100, 300, 600]\n",
    "sort_by_time = [True, False]\n",
    "partition_ratio = [[0.5, 0.25, 0.25], [0.6, 0.2, 0.2], [0.8, 0.1, 0.1]]\n",
    "\n",
    "\n",
    "\n",
    "# training_method = ['active_learning']\n",
    "# balanced = [True]\n",
    "# sampling_size = [10]\n",
    "# sort_by_time = [False]\n",
    "# partition_ratio = [[0.8, 0.1, 0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5848d2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-258cdd7c633d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpartition_ratio\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                     \u001b[0mmodel_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                         \u001b[0mmodel_result_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-a7d9182b119a>\u001b[0m in \u001b[0;36mtrial\u001b[1;34m(df, model_names, training_method, balance, sampling_size, sort_by_time, partition_ratio)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0msample_unlabeled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_unlabeled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msampling_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mseed_and_sample_unlabeled_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minitial_seed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_unlabeled\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mpipelines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_and_sample_unlabeled_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;31m# 3.2 Initial Model + Active Learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-570a25588350>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m     33\u001b[0m                 ])\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m#Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;31m# compute the testing accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;31m# n_jobs > 1 in can results in slower performance due to the overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;31m# of spawning threads.  See joblib issue #112.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(delayed(_fit_binary)(\n\u001b[0m\u001b[0;32m    282\u001b[0m             self.estimator, X, column, classes=[\n\u001b[0;32m    283\u001b[0m                 \u001b[1;34m\"not %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(estimator, X, y, classes)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_status_\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m             libsvm_sparse.libsvm_sparse_train(\n\u001b[0m\u001b[0;32m    302\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m                 \u001b[0mkernel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\svm\\_libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;34m\"\"\"base matrix class for compressed row- and column-oriented matrices\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_result_df = pd.DataFrame()\n",
    "index = 1\n",
    "model_name = \"SVC, KNN, Decision Tree, Random Forest, AdaBoost\"\n",
    "for tm in training_method:\n",
    "    for b in balanced:\n",
    "        for ss in sampling_size:\n",
    "            for t in sort_by_time:\n",
    "                for r in partition_ratio:\n",
    "                    print(index)\n",
    "                    model_output = trial(df, model_name, tm, b, ss, t, r)\n",
    "                    if index == 0:\n",
    "                        model_result_df = pd.DataFrame(model_output, index=index)\n",
    "                    else:\n",
    "                        model_result_df = model_result_df.append(pd.DataFrame([model_output],index=[index]))\n",
    "                    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce332de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c583f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result_df.to_csv('bucket_committee_model_result.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3340e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d77f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d908a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd8b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaeb2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db8c66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf644f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c54863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4b042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22e2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66099f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df87846b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
